{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Perceptrón",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Perceptron (Regresión logística)"
      ],
      "metadata": {
        "id": "OhvDPjldBYei"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocesamiento"
      ],
      "metadata": {
        "id": "uyXKFO0BTt3N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Librerias y archivos necesarios"
      ],
      "metadata": {
        "id": "FGdRqy4kBd5L"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65JBKO4kFAeN"
      },
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Comando para subir archivos\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Acomodando los datos"
      ],
      "metadata": {
        "id": "z_h97LkoOmqJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAoSZ4sQHydu"
      },
      "source": [
        "# Leyendo los datos separados por comas y convirtiendo en numpy\n",
        "df = pd.read_csv('diabetes.csv')\n",
        "data= df.to_numpy()\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dQ6sMAuIfji"
      },
      "source": [
        "# Se dividen los datos en entrenamiento y validación\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop('Outcome' , axis = 1)\n",
        "Y = df['Outcome']\n",
        "\n",
        "\n",
        "X_ent, X_val, Y_ent, Y_val = train_test_split(X, Y, test_size =0.1, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generando el modelo con Tensorflow"
      ],
      "metadata": {
        "id": "y08cQInbRy9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Entrada: Capa Input con el número de características de los datos\n",
        "#Salidas: Capa Totalmente conectada (Dense) con el número de neuronas\n",
        "#         igual a la cantidad de salidas que deseamos\n",
        "\n",
        "input_dt= tf.keras.layers.Input(shape= (8))\n",
        "x= tf.keras.layers.Dense(8, 'relu')(input_dt)\n",
        "x= tf.keras.layers.Dense(16, 'relu')(x)\n",
        "x= tf.keras.layers.Dense(16, 'relu')(x)\n",
        "salida= tf.keras.layers.Dense(1, 'sigmoid')(x)\n",
        "\n",
        "# Defininmos el modelo con la capa de entrada y salida\n",
        "model= tf.keras.Model(inputs= input_dt, outputs= salida)\n",
        "\n",
        "# Resumimos el modelo para verificar que sea la arquitectura deseada\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# Compilación del modelo;\n",
        "#   Optimizador: Adam\n",
        "#   Loss: Binary crossentropy\n",
        "#   Epocas: Número de veces que se va a entrenar el modelo\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(), loss = 'binary_crossentropy', metrics= ['accuracy'])\n",
        "history= model.fit(X_ent, Y_ent, validation_data= [X_val, Y_val], epochs= 1000)"
      ],
      "metadata": {
        "id": "BEHvGbLiWQSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Revisando el entrenamiento"
      ],
      "metadata": {
        "id": "bjJtY12MTlxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc= history.history['accuracy']\n",
        "loss= history.history['loss']\n",
        "acc_val= history.history['val_accuracy']\n",
        "loss_val= history.history['val_loss']\n",
        "\n",
        "def graficar(val_1, val_2, titulo, ylabel):\n",
        "  epochs= np.arange(len(history.history['accuracy']))\n",
        "  plt.plot(epochs, val_1, 'g', label= 'Ent')\n",
        "  plt.plot(epochs, val_2, 'b', label= 'Val')\n",
        "  plt.xlabel('Epoca')\n",
        "  plt.ylabel(ylabel)\n",
        "  plt.title(titulo)\n",
        "  plt.legend(loc='lower right')\n",
        "  plt.show()\n",
        "\n",
        "graficar(acc, acc_val, 'Exactitud ent y val', 'Exactitud')\n",
        "graficar(loss, loss_val, 'Loss ent y val', 'Loss')"
      ],
      "metadata": {
        "id": "d15w7JagZ4ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vCK7-6Oshfyw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}