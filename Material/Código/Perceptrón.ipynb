{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Perceptrón",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Perceptron (Regresión logística)"
      ],
      "metadata": {
        "id": "OhvDPjldBYei"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocesamiento"
      ],
      "metadata": {
        "id": "uyXKFO0BTt3N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Librerias y archivos necesarios"
      ],
      "metadata": {
        "id": "FGdRqy4kBd5L"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65JBKO4kFAeN",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "2b8ebbff-37a3-49a5-9286-ed23e49f0ae6"
      },
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Comando para subir archivos\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-01b03006-ab88-4ece-a109-c8c7678b3a45\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-01b03006-ab88-4ece-a109-c8c7678b3a45\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving diabetes.csv to diabetes (1).csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'diabetes.csv': b'Pregnancies,Glucose,BloodPressure,SkinThickness,Insulin,BMI,DiabetesPedigreeFunction,Age,Outcome\\r\\n6,148,72,35,0,33.6,0.627,50,1\\r\\n1,85,66,29,0,26.6,0.351,31,0\\r\\n8,183,64,0,0,23.3,0.672,32,1\\r\\n1,89,66,23,94,28.1,0.167,21,0\\r\\n0,137,40,35,168,43.1,2.288,33,1\\r\\n5,116,74,0,0,25.6,0.201,30,0\\r\\n3,78,50,32,88,31,0.248,26,1\\r\\n10,115,0,0,0,35.3,0.134,29,0\\r\\n2,197,70,45,543,30.5,0.158,53,1\\r\\n8,125,96,0,0,0,0.232,54,1\\r\\n4,110,92,0,0,37.6,0.191,30,0\\r\\n10,168,74,0,0,38,0.537,34,1\\r\\n10,139,80,0,0,27.1,1.441,57,0\\r\\n1,189,60,23,846,30.1,0.398,59,1\\r\\n5,166,72,19,175,25.8,0.587,51,1\\r\\n7,100,0,0,0,30,0.484,32,1\\r\\n0,118,84,47,230,45.8,0.551,31,1\\r\\n7,107,74,0,0,29.6,0.254,31,1\\r\\n1,103,30,38,83,43.3,0.183,33,0\\r\\n1,115,70,30,96,34.6,0.529,32,1\\r\\n3,126,88,41,235,39.3,0.704,27,0\\r\\n8,99,84,0,0,35.4,0.388,50,0\\r\\n7,196,90,0,0,39.8,0.451,41,1\\r\\n9,119,80,35,0,29,0.263,29,1\\r\\n11,143,94,33,146,36.6,0.254,51,1\\r\\n10,125,70,26,115,31.1,0.205,41,1\\r\\n7,147,76,0,0,39.4,0.257,43,1\\r\\n1,97,66,15,140,23.2,0.487,22,0\\r\\n13,145,82,19,110,22.2,0.245,57,0\\r\\n5,117,92,0,0,34.1,0.337,38,0\\r\\n5,109,75,26,0,36,0.546,60,0\\r\\n3,158,76,36,245,31.6,0.851,28,1\\r\\n3,88,58,11,54,24.8,0.267,22,0\\r\\n6,92,92,0,0,19.9,0.188,28,0\\r\\n10,122,78,31,0,27.6,0.512,45,0\\r\\n4,103,60,33,192,24,0.966,33,0\\r\\n11,138,76,0,0,33.2,0.42,35,0\\r\\n9,102,76,37,0,32.9,0.665,46,1\\r\\n2,90,68,42,0,38.2,0.503,27,1\\r\\n4,111,72,47,207,37.1,1.39,56,1\\r\\n3,180,64,25,70,34,0.271,26,0\\r\\n7,133,84,0,0,40.2,0.696,37,0\\r\\n7,106,92,18,0,22.7,0.235,48,0\\r\\n9,171,110,24,240,45.4,0.721,54,1\\r\\n7,159,64,0,0,27.4,0.294,40,0\\r\\n0,180,66,39,0,42,1.893,25,1\\r\\n1,146,56,0,0,29.7,0.564,29,0\\r\\n2,71,70,27,0,28,0.586,22,0\\r\\n7,103,66,32,0,39.1,0.344,31,1\\r\\n7,105,0,0,0,0,0.305,24,0\\r\\n1,103,80,11,82,19.4,0.491,22,0\\r\\n1,101,50,15,36,24.2,0.526,26,0\\r\\n5,88,66,21,23,24.4,0.342,30,0\\r\\n8,176,90,34,300,33.7,0.467,58,1\\r\\n7,150,66,42,342,34.7,0.718,42,0\\r\\n1,73,50,10,0,23,0.248,21,0\\r\\n7,187,68,39,304,37.7,0.254,41,1\\r\\n0,100,88,60,110,46.8,0.962,31,0\\r\\n0,146,82,0,0,40.5,1.781,44,0\\r\\n0,105,64,41,142,41.5,0.173,22,0\\r\\n2,84,0,0,0,0,0.304,21,0\\r\\n8,133,72,0,0,32.9,0.27,39,1\\r\\n5,44,62,0,0,25,0.587,36,0\\r\\n2,141,58,34,128,25.4,0.699,24,0\\r\\n7,114,66,0,0,32.8,0.258,42,1\\r\\n5,99,74,27,0,29,0.203,32,0\\r\\n0,109,88,30,0,32.5,0.855,38,1\\r\\n2,109,92,0,0,42.7,0.845,54,0\\r\\n1,95,66,13,38,19.6,0.334,25,0\\r\\n4,146,85,27,100,28.9,0.189,27,0\\r\\n2,100,66,20,90,32.9,0.867,28,1\\r\\n5,139,64,35,140,28.6,0.411,26,0\\r\\n13,126,90,0,0,43.4,0.583,42,1\\r\\n4,129,86,20,270,35.1,0.231,23,0\\r\\n1,79,75,30,0,32,0.396,22,0\\r\\n1,0,48,20,0,24.7,0.14,22,0\\r\\n7,62,78,0,0,32.6,0.391,41,0\\r\\n5,95,72,33,0,37.7,0.37,27,0\\r\\n0,131,0,0,0,43.2,0.27,26,1\\r\\n2,112,66,22,0,25,0.307,24,0\\r\\n3,113,44,13,0,22.4,0.14,22,0\\r\\n2,74,0,0,0,0,0.102,22,0\\r\\n7,83,78,26,71,29.3,0.767,36,0\\r\\n0,101,65,28,0,24.6,0.237,22,0\\r\\n5,137,108,0,0,48.8,0.227,37,1\\r\\n2,110,74,29,125,32.4,0.698,27,0\\r\\n13,106,72,54,0,36.6,0.178,45,0\\r\\n2,100,68,25,71,38.5,0.324,26,0\\r\\n15,136,70,32,110,37.1,0.153,43,1\\r\\n1,107,68,19,0,26.5,0.165,24,0\\r\\n1,80,55,0,0,19.1,0.258,21,0\\r\\n4,123,80,15,176,32,0.443,34,0\\r\\n7,81,78,40,48,46.7,0.261,42,0\\r\\n4,134,72,0,0,23.8,0.277,60,1\\r\\n2,142,82,18,64,24.7,0.761,21,0\\r\\n6,144,72,27,228,33.9,0.255,40,0\\r\\n2,92,62,28,0,31.6,0.13,24,0\\r\\n1,71,48,18,76,20.4,0.323,22,0\\r\\n6,93,50,30,64,28.7,0.356,23,0\\r\\n1,122,90,51,220,49.7,0.325,31,1\\r\\n1,163,72,0,0,39,1.222,33,1\\r\\n1,151,60,0,0,26.1,0.179,22,0\\r\\n0,125,96,0,0,22.5,0.262,21,0\\r\\n1,81,72,18,40,26.6,0.283,24,0\\r\\n2,85,65,0,0,39.6,0.93,27,0\\r\\n1,126,56,29,152,28.7,0.801,21,0\\r\\n1,96,122,0,0,22.4,0.207,27,0\\r\\n4,144,58,28,140,29.5,0.287,37,0\\r\\n3,83,58,31,18,34.3,0.336,25,0\\r\\n0,95,85,25,36,37.4,0.247,24,1\\r\\n3,171,72,33,135,33.3,0.199,24,1\\r\\n8,155,62,26,495,34,0.543,46,1\\r\\n1,89,76,34,37,31.2,0.192,23,0\\r\\n4,76,62,0,0,34,0.391,25,0\\r\\n7,160,54,32,175,30.5,0.588,39,1\\r\\n4,146,92,0,0,31.2,0.539,61,1\\r\\n5,124,74,0,0,34,0.22,38,1\\r\\n5,78,48,0,0,33.7,0.654,25,0\\r\\n4,97,60,23,0,28.2,0.443,22,0\\r\\n4,99,76,15,51,23.2,0.223,21,0\\r\\n0,162,76,56,100,53.2,0.759,25,1\\r\\n6,111,64,39,0,34.2,0.26,24,0\\r\\n2,107,74,30,100,33.6,0.404,23,0\\r\\n5,132,80,0,0,26.8,0.186,69,0\\r\\n0,113,76,0,0,33.3,0.278,23,1\\r\\n1,88,30,42,99,55,0.496,26,1\\r\\n3,120,70,30,135,42.9,0.452,30,0\\r\\n1,118,58,36,94,33.3,0.261,23,0\\r\\n1,117,88,24,145,34.5,0.403,40,1\\r\\n0,105,84,0,0,27.9,0.741,62,1\\r\\n4,173,70,14,168,29.7,0.361,33,1\\r\\n9,122,56,0,0,33.3,1.114,33,1\\r\\n3,170,64,37,225,34.5,0.356,30,1\\r\\n8,84,74,31,0,38.3,0.457,39,0\\r\\n2,96,68,13,49,21.1,0.647,26,0\\r\\n2,125,60,20,140,33.8,0.088,31,0\\r\\n0,100,70,26,50,30.8,0.597,21,0\\r\\n0,93,60,25,92,28.7,0.532,22,0\\r\\n0,129,80,0,0,31.2,0.703,29,0\\r\\n5,105,72,29,325,36.9,0.159,28,0\\r\\n3,128,78,0,0,21.1,0.268,55,0\\r\\n5,106,82,30,0,39.5,0.286,38,0\\r\\n2,108,52,26,63,32.5,0.318,22,0\\r\\n10,108,66,0,0,32.4,0.272,42,1\\r\\n4,154,62,31,284,32.8,0.237,23,0\\r\\n0,102,75,23,0,0,0.572,21,0\\r\\n9,57,80,37,0,32.8,0.096,41,0\\r\\n2,106,64,35,119,30.5,1.4,34,0\\r\\n5,147,78,0,0,33.7,0.218,65,0\\r\\n2,90,70,17,0,27.3,0.085,22,0\\r\\n1,136,74,50,204,37.4,0.399,24,0\\r\\n4,114,65,0,0,21.9,0.432,37,0\\r\\n9,156,86,28,155,34.3,1.189,42,1\\r\\n1,153,82,42,485,40.6,0.687,23,0\\r\\n8,188,78,0,0,47.9,0.137,43,1\\r\\n7,152,88,44,0,50,0.337,36,1\\r\\n2,99,52,15,94,24.6,0.637,21,0\\r\\n1,109,56,21,135,25.2,0.833,23,0\\r\\n2,88,74,19,53,29,0.229,22,0\\r\\n17,163,72,41,114,40.9,0.817,47,1\\r\\n4,151,90,38,0,29.7,0.294,36,0\\r\\n7,102,74,40,105,37.2,0.204,45,0\\r\\n0,114,80,34,285,44.2,0.167,27,0\\r\\n2,100,64,23,0,29.7,0.368,21,0\\r\\n0,131,88,0,0,31.6,0.743,32,1\\r\\n6,104,74,18,156,29.9,0.722,41,1\\r\\n3,148,66,25,0,32.5,0.256,22,0\\r\\n4,120,68,0,0,29.6,0.709,34,0\\r\\n4,110,66,0,0,31.9,0.471,29,0\\r\\n3,111,90,12,78,28.4,0.495,29,0\\r\\n6,102,82,0,0,30.8,0.18,36,1\\r\\n6,134,70,23,130,35.4,0.542,29,1\\r\\n2,87,0,23,0,28.9,0.773,25,0\\r\\n1,79,60,42,48,43.5,0.678,23,0\\r\\n2,75,64,24,55,29.7,0.37,33,0\\r\\n8,179,72,42,130,32.7,0.719,36,1\\r\\n6,85,78,0,0,31.2,0.382,42,0\\r\\n0,129,110,46,130,67.1,0.319,26,1\\r\\n5,143,78,0,0,45,0.19,47,0\\r\\n5,130,82,0,0,39.1,0.956,37,1\\r\\n6,87,80,0,0,23.2,0.084,32,0\\r\\n0,119,64,18,92,34.9,0.725,23,0\\r\\n1,0,74,20,23,27.7,0.299,21,0\\r\\n5,73,60,0,0,26.8,0.268,27,0\\r\\n4,141,74,0,0,27.6,0.244,40,0\\r\\n7,194,68,28,0,35.9,0.745,41,1\\r\\n8,181,68,36,495,30.1,0.615,60,1\\r\\n1,128,98,41,58,32,1.321,33,1\\r\\n8,109,76,39,114,27.9,0.64,31,1\\r\\n5,139,80,35,160,31.6,0.361,25,1\\r\\n3,111,62,0,0,22.6,0.142,21,0\\r\\n9,123,70,44,94,33.1,0.374,40,0\\r\\n7,159,66,0,0,30.4,0.383,36,1\\r\\n11,135,0,0,0,52.3,0.578,40,1\\r\\n8,85,55,20,0,24.4,0.136,42,0\\r\\n5,158,84,41,210,39.4,0.395,29,1\\r\\n1,105,58,0,0,24.3,0.187,21,0\\r\\n3,107,62,13,48,22.9,0.678,23,1\\r\\n4,109,64,44,99,34.8,0.905,26,1\\r\\n4,148,60,27,318,30.9,0.15,29,1\\r\\n0,113,80,16,0,31,0.874,21,0\\r\\n1,138,82,0,0,40.1,0.236,28,0\\r\\n0,108,68,20,0,27.3,0.787,32,0\\r\\n2,99,70,16,44,20.4,0.235,27,0\\r\\n6,103,72,32,190,37.7,0.324,55,0\\r\\n5,111,72,28,0,23.9,0.407,27,0\\r\\n8,196,76,29,280,37.5,0.605,57,1\\r\\n5,162,104,0,0,37.7,0.151,52,1\\r\\n1,96,64,27,87,33.2,0.289,21,0\\r\\n7,184,84,33,0,35.5,0.355,41,1\\r\\n2,81,60,22,0,27.7,0.29,25,0\\r\\n0,147,85,54,0,42.8,0.375,24,0\\r\\n7,179,95,31,0,34.2,0.164,60,0\\r\\n0,140,65,26,130,42.6,0.431,24,1\\r\\n9,112,82,32,175,34.2,0.26,36,1\\r\\n12,151,70,40,271,41.8,0.742,38,1\\r\\n5,109,62,41,129,35.8,0.514,25,1\\r\\n6,125,68,30,120,30,0.464,32,0\\r\\n5,85,74,22,0,29,1.224,32,1\\r\\n5,112,66,0,0,37.8,0.261,41,1\\r\\n0,177,60,29,478,34.6,1.072,21,1\\r\\n2,158,90,0,0,31.6,0.805,66,1\\r\\n7,119,0,0,0,25.2,0.209,37,0\\r\\n7,142,60,33,190,28.8,0.687,61,0\\r\\n1,100,66,15,56,23.6,0.666,26,0\\r\\n1,87,78,27,32,34.6,0.101,22,0\\r\\n0,101,76,0,0,35.7,0.198,26,0\\r\\n3,162,52,38,0,37.2,0.652,24,1\\r\\n4,197,70,39,744,36.7,2.329,31,0\\r\\n0,117,80,31,53,45.2,0.089,24,0\\r\\n4,142,86,0,0,44,0.645,22,1\\r\\n6,134,80,37,370,46.2,0.238,46,1\\r\\n1,79,80,25,37,25.4,0.583,22,0\\r\\n4,122,68,0,0,35,0.394,29,0\\r\\n3,74,68,28,45,29.7,0.293,23,0\\r\\n4,171,72,0,0,43.6,0.479,26,1\\r\\n7,181,84,21,192,35.9,0.586,51,1\\r\\n0,179,90,27,0,44.1,0.686,23,1\\r\\n9,164,84,21,0,30.8,0.831,32,1\\r\\n0,104,76,0,0,18.4,0.582,27,0\\r\\n1,91,64,24,0,29.2,0.192,21,0\\r\\n4,91,70,32,88,33.1,0.446,22,0\\r\\n3,139,54,0,0,25.6,0.402,22,1\\r\\n6,119,50,22,176,27.1,1.318,33,1\\r\\n2,146,76,35,194,38.2,0.329,29,0\\r\\n9,184,85,15,0,30,1.213,49,1\\r\\n10,122,68,0,0,31.2,0.258,41,0\\r\\n0,165,90,33,680,52.3,0.427,23,0\\r\\n9,124,70,33,402,35.4,0.282,34,0\\r\\n1,111,86,19,0,30.1,0.143,23,0\\r\\n9,106,52,0,0,31.2,0.38,42,0\\r\\n2,129,84,0,0,28,0.284,27,0\\r\\n2,90,80,14,55,24.4,0.249,24,0\\r\\n0,86,68,32,0,35.8,0.238,25,0\\r\\n12,92,62,7,258,27.6,0.926,44,1\\r\\n1,113,64,35,0,33.6,0.543,21,1\\r\\n3,111,56,39,0,30.1,0.557,30,0\\r\\n2,114,68,22,0,28.7,0.092,25,0\\r\\n1,193,50,16,375,25.9,0.655,24,0\\r\\n11,155,76,28,150,33.3,1.353,51,1\\r\\n3,191,68,15,130,30.9,0.299,34,0\\r\\n3,141,0,0,0,30,0.761,27,1\\r\\n4,95,70,32,0,32.1,0.612,24,0\\r\\n3,142,80,15,0,32.4,0.2,63,0\\r\\n4,123,62,0,0,32,0.226,35,1\\r\\n5,96,74,18,67,33.6,0.997,43,0\\r\\n0,138,0,0,0,36.3,0.933,25,1\\r\\n2,128,64,42,0,40,1.101,24,0\\r\\n0,102,52,0,0,25.1,0.078,21,0\\r\\n2,146,0,0,0,27.5,0.24,28,1\\r\\n10,101,86,37,0,45.6,1.136,38,1\\r\\n2,108,62,32,56,25.2,0.128,21,0\\r\\n3,122,78,0,0,23,0.254,40,0\\r\\n1,71,78,50,45,33.2,0.422,21,0\\r\\n13,106,70,0,0,34.2,0.251,52,0\\r\\n2,100,70,52,57,40.5,0.677,25,0\\r\\n7,106,60,24,0,26.5,0.296,29,1\\r\\n0,104,64,23,116,27.8,0.454,23,0\\r\\n5,114,74,0,0,24.9,0.744,57,0\\r\\n2,108,62,10,278,25.3,0.881,22,0\\r\\n0,146,70,0,0,37.9,0.334,28,1\\r\\n10,129,76,28,122,35.9,0.28,39,0\\r\\n7,133,88,15,155,32.4,0.262,37,0\\r\\n7,161,86,0,0,30.4,0.165,47,1\\r\\n2,108,80,0,0,27,0.259,52,1\\r\\n7,136,74,26,135,26,0.647,51,0\\r\\n5,155,84,44,545,38.7,0.619,34,0\\r\\n1,119,86,39,220,45.6,0.808,29,1\\r\\n4,96,56,17,49,20.8,0.34,26,0\\r\\n5,108,72,43,75,36.1,0.263,33,0\\r\\n0,78,88,29,40,36.9,0.434,21,0\\r\\n0,107,62,30,74,36.6,0.757,25,1\\r\\n2,128,78,37,182,43.3,1.224,31,1\\r\\n1,128,48,45,194,40.5,0.613,24,1\\r\\n0,161,50,0,0,21.9,0.254,65,0\\r\\n6,151,62,31,120,35.5,0.692,28,0\\r\\n2,146,70,38,360,28,0.337,29,1\\r\\n0,126,84,29,215,30.7,0.52,24,0\\r\\n14,100,78,25,184,36.6,0.412,46,1\\r\\n8,112,72,0,0,23.6,0.84,58,0\\r\\n0,167,0,0,0,32.3,0.839,30,1\\r\\n2,144,58,33,135,31.6,0.422,25,1\\r\\n5,77,82,41,42,35.8,0.156,35,0\\r\\n5,115,98,0,0,52.9,0.209,28,1\\r\\n3,150,76,0,0,21,0.207,37,0\\r\\n2,120,76,37,105,39.7,0.215,29,0\\r\\n10,161,68,23,132,25.5,0.326,47,1\\r\\n0,137,68,14,148,24.8,0.143,21,0\\r\\n0,128,68,19,180,30.5,1.391,25,1\\r\\n2,124,68,28,205,32.9,0.875,30,1\\r\\n6,80,66,30,0,26.2,0.313,41,0\\r\\n0,106,70,37,148,39.4,0.605,22,0\\r\\n2,155,74,17,96,26.6,0.433,27,1\\r\\n3,113,50,10,85,29.5,0.626,25,0\\r\\n7,109,80,31,0,35.9,1.127,43,1\\r\\n2,112,68,22,94,34.1,0.315,26,0\\r\\n3,99,80,11,64,19.3,0.284,30,0\\r\\n3,182,74,0,0,30.5,0.345,29,1\\r\\n3,115,66,39,140,38.1,0.15,28,0\\r\\n6,194,78,0,0,23.5,0.129,59,1\\r\\n4,129,60,12,231,27.5,0.527,31,0\\r\\n3,112,74,30,0,31.6,0.197,25,1\\r\\n0,124,70,20,0,27.4,0.254,36,1\\r\\n13,152,90,33,29,26.8,0.731,43,1\\r\\n2,112,75,32,0,35.7,0.148,21,0\\r\\n1,157,72,21,168,25.6,0.123,24,0\\r\\n1,122,64,32,156,35.1,0.692,30,1\\r\\n10,179,70,0,0,35.1,0.2,37,0\\r\\n2,102,86,36,120,45.5,0.127,23,1\\r\\n6,105,70,32,68,30.8,0.122,37,0\\r\\n8,118,72,19,0,23.1,1.476,46,0\\r\\n2,87,58,16,52,32.7,0.166,25,0\\r\\n1,180,0,0,0,43.3,0.282,41,1\\r\\n12,106,80,0,0,23.6,0.137,44,0\\r\\n1,95,60,18,58,23.9,0.26,22,0\\r\\n0,165,76,43,255,47.9,0.259,26,0\\r\\n0,117,0,0,0,33.8,0.932,44,0\\r\\n5,115,76,0,0,31.2,0.343,44,1\\r\\n9,152,78,34,171,34.2,0.893,33,1\\r\\n7,178,84,0,0,39.9,0.331,41,1\\r\\n1,130,70,13,105,25.9,0.472,22,0\\r\\n1,95,74,21,73,25.9,0.673,36,0\\r\\n1,0,68,35,0,32,0.389,22,0\\r\\n5,122,86,0,0,34.7,0.29,33,0\\r\\n8,95,72,0,0,36.8,0.485,57,0\\r\\n8,126,88,36,108,38.5,0.349,49,0\\r\\n1,139,46,19,83,28.7,0.654,22,0\\r\\n3,116,0,0,0,23.5,0.187,23,0\\r\\n3,99,62,19,74,21.8,0.279,26,0\\r\\n5,0,80,32,0,41,0.346,37,1\\r\\n4,92,80,0,0,42.2,0.237,29,0\\r\\n4,137,84,0,0,31.2,0.252,30,0\\r\\n3,61,82,28,0,34.4,0.243,46,0\\r\\n1,90,62,12,43,27.2,0.58,24,0\\r\\n3,90,78,0,0,42.7,0.559,21,0\\r\\n9,165,88,0,0,30.4,0.302,49,1\\r\\n1,125,50,40,167,33.3,0.962,28,1\\r\\n13,129,0,30,0,39.9,0.569,44,1\\r\\n12,88,74,40,54,35.3,0.378,48,0\\r\\n1,196,76,36,249,36.5,0.875,29,1\\r\\n5,189,64,33,325,31.2,0.583,29,1\\r\\n5,158,70,0,0,29.8,0.207,63,0\\r\\n5,103,108,37,0,39.2,0.305,65,0\\r\\n4,146,78,0,0,38.5,0.52,67,1\\r\\n4,147,74,25,293,34.9,0.385,30,0\\r\\n5,99,54,28,83,34,0.499,30,0\\r\\n6,124,72,0,0,27.6,0.368,29,1\\r\\n0,101,64,17,0,21,0.252,21,0\\r\\n3,81,86,16,66,27.5,0.306,22,0\\r\\n1,133,102,28,140,32.8,0.234,45,1\\r\\n3,173,82,48,465,38.4,2.137,25,1\\r\\n0,118,64,23,89,0,1.731,21,0\\r\\n0,84,64,22,66,35.8,0.545,21,0\\r\\n2,105,58,40,94,34.9,0.225,25,0\\r\\n2,122,52,43,158,36.2,0.816,28,0\\r\\n12,140,82,43,325,39.2,0.528,58,1\\r\\n0,98,82,15,84,25.2,0.299,22,0\\r\\n1,87,60,37,75,37.2,0.509,22,0\\r\\n4,156,75,0,0,48.3,0.238,32,1\\r\\n0,93,100,39,72,43.4,1.021,35,0\\r\\n1,107,72,30,82,30.8,0.821,24,0\\r\\n0,105,68,22,0,20,0.236,22,0\\r\\n1,109,60,8,182,25.4,0.947,21,0\\r\\n1,90,62,18,59,25.1,1.268,25,0\\r\\n1,125,70,24,110,24.3,0.221,25,0\\r\\n1,119,54,13,50,22.3,0.205,24,0\\r\\n5,116,74,29,0,32.3,0.66,35,1\\r\\n8,105,100,36,0,43.3,0.239,45,1\\r\\n5,144,82,26,285,32,0.452,58,1\\r\\n3,100,68,23,81,31.6,0.949,28,0\\r\\n1,100,66,29,196,32,0.444,42,0\\r\\n5,166,76,0,0,45.7,0.34,27,1\\r\\n1,131,64,14,415,23.7,0.389,21,0\\r\\n4,116,72,12,87,22.1,0.463,37,0\\r\\n4,158,78,0,0,32.9,0.803,31,1\\r\\n2,127,58,24,275,27.7,1.6,25,0\\r\\n3,96,56,34,115,24.7,0.944,39,0\\r\\n0,131,66,40,0,34.3,0.196,22,1\\r\\n3,82,70,0,0,21.1,0.389,25,0\\r\\n3,193,70,31,0,34.9,0.241,25,1\\r\\n4,95,64,0,0,32,0.161,31,1\\r\\n6,137,61,0,0,24.2,0.151,55,0\\r\\n5,136,84,41,88,35,0.286,35,1\\r\\n9,72,78,25,0,31.6,0.28,38,0\\r\\n5,168,64,0,0,32.9,0.135,41,1\\r\\n2,123,48,32,165,42.1,0.52,26,0\\r\\n4,115,72,0,0,28.9,0.376,46,1\\r\\n0,101,62,0,0,21.9,0.336,25,0\\r\\n8,197,74,0,0,25.9,1.191,39,1\\r\\n1,172,68,49,579,42.4,0.702,28,1\\r\\n6,102,90,39,0,35.7,0.674,28,0\\r\\n1,112,72,30,176,34.4,0.528,25,0\\r\\n1,143,84,23,310,42.4,1.076,22,0\\r\\n1,143,74,22,61,26.2,0.256,21,0\\r\\n0,138,60,35,167,34.6,0.534,21,1\\r\\n3,173,84,33,474,35.7,0.258,22,1\\r\\n1,97,68,21,0,27.2,1.095,22,0\\r\\n4,144,82,32,0,38.5,0.554,37,1\\r\\n1,83,68,0,0,18.2,0.624,27,0\\r\\n3,129,64,29,115,26.4,0.219,28,1\\r\\n1,119,88,41,170,45.3,0.507,26,0\\r\\n2,94,68,18,76,26,0.561,21,0\\r\\n0,102,64,46,78,40.6,0.496,21,0\\r\\n2,115,64,22,0,30.8,0.421,21,0\\r\\n8,151,78,32,210,42.9,0.516,36,1\\r\\n4,184,78,39,277,37,0.264,31,1\\r\\n0,94,0,0,0,0,0.256,25,0\\r\\n1,181,64,30,180,34.1,0.328,38,1\\r\\n0,135,94,46,145,40.6,0.284,26,0\\r\\n1,95,82,25,180,35,0.233,43,1\\r\\n2,99,0,0,0,22.2,0.108,23,0\\r\\n3,89,74,16,85,30.4,0.551,38,0\\r\\n1,80,74,11,60,30,0.527,22,0\\r\\n2,139,75,0,0,25.6,0.167,29,0\\r\\n1,90,68,8,0,24.5,1.138,36,0\\r\\n0,141,0,0,0,42.4,0.205,29,1\\r\\n12,140,85,33,0,37.4,0.244,41,0\\r\\n5,147,75,0,0,29.9,0.434,28,0\\r\\n1,97,70,15,0,18.2,0.147,21,0\\r\\n6,107,88,0,0,36.8,0.727,31,0\\r\\n0,189,104,25,0,34.3,0.435,41,1\\r\\n2,83,66,23,50,32.2,0.497,22,0\\r\\n4,117,64,27,120,33.2,0.23,24,0\\r\\n8,108,70,0,0,30.5,0.955,33,1\\r\\n4,117,62,12,0,29.7,0.38,30,1\\r\\n0,180,78,63,14,59.4,2.42,25,1\\r\\n1,100,72,12,70,25.3,0.658,28,0\\r\\n0,95,80,45,92,36.5,0.33,26,0\\r\\n0,104,64,37,64,33.6,0.51,22,1\\r\\n0,120,74,18,63,30.5,0.285,26,0\\r\\n1,82,64,13,95,21.2,0.415,23,0\\r\\n2,134,70,0,0,28.9,0.542,23,1\\r\\n0,91,68,32,210,39.9,0.381,25,0\\r\\n2,119,0,0,0,19.6,0.832,72,0\\r\\n2,100,54,28,105,37.8,0.498,24,0\\r\\n14,175,62,30,0,33.6,0.212,38,1\\r\\n1,135,54,0,0,26.7,0.687,62,0\\r\\n5,86,68,28,71,30.2,0.364,24,0\\r\\n10,148,84,48,237,37.6,1.001,51,1\\r\\n9,134,74,33,60,25.9,0.46,81,0\\r\\n9,120,72,22,56,20.8,0.733,48,0\\r\\n1,71,62,0,0,21.8,0.416,26,0\\r\\n8,74,70,40,49,35.3,0.705,39,0\\r\\n5,88,78,30,0,27.6,0.258,37,0\\r\\n10,115,98,0,0,24,1.022,34,0\\r\\n0,124,56,13,105,21.8,0.452,21,0\\r\\n0,74,52,10,36,27.8,0.269,22,0\\r\\n0,97,64,36,100,36.8,0.6,25,0\\r\\n8,120,0,0,0,30,0.183,38,1\\r\\n6,154,78,41,140,46.1,0.571,27,0\\r\\n1,144,82,40,0,41.3,0.607,28,0\\r\\n0,137,70,38,0,33.2,0.17,22,0\\r\\n0,119,66,27,0,38.8,0.259,22,0\\r\\n7,136,90,0,0,29.9,0.21,50,0\\r\\n4,114,64,0,0,28.9,0.126,24,0\\r\\n0,137,84,27,0,27.3,0.231,59,0\\r\\n2,105,80,45,191,33.7,0.711,29,1\\r\\n7,114,76,17,110,23.8,0.466,31,0\\r\\n8,126,74,38,75,25.9,0.162,39,0\\r\\n4,132,86,31,0,28,0.419,63,0\\r\\n3,158,70,30,328,35.5,0.344,35,1\\r\\n0,123,88,37,0,35.2,0.197,29,0\\r\\n4,85,58,22,49,27.8,0.306,28,0\\r\\n0,84,82,31,125,38.2,0.233,23,0\\r\\n0,145,0,0,0,44.2,0.63,31,1\\r\\n0,135,68,42,250,42.3,0.365,24,1\\r\\n1,139,62,41,480,40.7,0.536,21,0\\r\\n0,173,78,32,265,46.5,1.159,58,0\\r\\n4,99,72,17,0,25.6,0.294,28,0\\r\\n8,194,80,0,0,26.1,0.551,67,0\\r\\n2,83,65,28,66,36.8,0.629,24,0\\r\\n2,89,90,30,0,33.5,0.292,42,0\\r\\n4,99,68,38,0,32.8,0.145,33,0\\r\\n4,125,70,18,122,28.9,1.144,45,1\\r\\n3,80,0,0,0,0,0.174,22,0\\r\\n6,166,74,0,0,26.6,0.304,66,0\\r\\n5,110,68,0,0,26,0.292,30,0\\r\\n2,81,72,15,76,30.1,0.547,25,0\\r\\n7,195,70,33,145,25.1,0.163,55,1\\r\\n6,154,74,32,193,29.3,0.839,39,0\\r\\n2,117,90,19,71,25.2,0.313,21,0\\r\\n3,84,72,32,0,37.2,0.267,28,0\\r\\n6,0,68,41,0,39,0.727,41,1\\r\\n7,94,64,25,79,33.3,0.738,41,0\\r\\n3,96,78,39,0,37.3,0.238,40,0\\r\\n10,75,82,0,0,33.3,0.263,38,0\\r\\n0,180,90,26,90,36.5,0.314,35,1\\r\\n1,130,60,23,170,28.6,0.692,21,0\\r\\n2,84,50,23,76,30.4,0.968,21,0\\r\\n8,120,78,0,0,25,0.409,64,0\\r\\n12,84,72,31,0,29.7,0.297,46,1\\r\\n0,139,62,17,210,22.1,0.207,21,0\\r\\n9,91,68,0,0,24.2,0.2,58,0\\r\\n2,91,62,0,0,27.3,0.525,22,0\\r\\n3,99,54,19,86,25.6,0.154,24,0\\r\\n3,163,70,18,105,31.6,0.268,28,1\\r\\n9,145,88,34,165,30.3,0.771,53,1\\r\\n7,125,86,0,0,37.6,0.304,51,0\\r\\n13,76,60,0,0,32.8,0.18,41,0\\r\\n6,129,90,7,326,19.6,0.582,60,0\\r\\n2,68,70,32,66,25,0.187,25,0\\r\\n3,124,80,33,130,33.2,0.305,26,0\\r\\n6,114,0,0,0,0,0.189,26,0\\r\\n9,130,70,0,0,34.2,0.652,45,1\\r\\n3,125,58,0,0,31.6,0.151,24,0\\r\\n3,87,60,18,0,21.8,0.444,21,0\\r\\n1,97,64,19,82,18.2,0.299,21,0\\r\\n3,116,74,15,105,26.3,0.107,24,0\\r\\n0,117,66,31,188,30.8,0.493,22,0\\r\\n0,111,65,0,0,24.6,0.66,31,0\\r\\n2,122,60,18,106,29.8,0.717,22,0\\r\\n0,107,76,0,0,45.3,0.686,24,0\\r\\n1,86,66,52,65,41.3,0.917,29,0\\r\\n6,91,0,0,0,29.8,0.501,31,0\\r\\n1,77,56,30,56,33.3,1.251,24,0\\r\\n4,132,0,0,0,32.9,0.302,23,1\\r\\n0,105,90,0,0,29.6,0.197,46,0\\r\\n0,57,60,0,0,21.7,0.735,67,0\\r\\n0,127,80,37,210,36.3,0.804,23,0\\r\\n3,129,92,49,155,36.4,0.968,32,1\\r\\n8,100,74,40,215,39.4,0.661,43,1\\r\\n3,128,72,25,190,32.4,0.549,27,1\\r\\n10,90,85,32,0,34.9,0.825,56,1\\r\\n4,84,90,23,56,39.5,0.159,25,0\\r\\n1,88,78,29,76,32,0.365,29,0\\r\\n8,186,90,35,225,34.5,0.423,37,1\\r\\n5,187,76,27,207,43.6,1.034,53,1\\r\\n4,131,68,21,166,33.1,0.16,28,0\\r\\n1,164,82,43,67,32.8,0.341,50,0\\r\\n4,189,110,31,0,28.5,0.68,37,0\\r\\n1,116,70,28,0,27.4,0.204,21,0\\r\\n3,84,68,30,106,31.9,0.591,25,0\\r\\n6,114,88,0,0,27.8,0.247,66,0\\r\\n1,88,62,24,44,29.9,0.422,23,0\\r\\n1,84,64,23,115,36.9,0.471,28,0\\r\\n7,124,70,33,215,25.5,0.161,37,0\\r\\n1,97,70,40,0,38.1,0.218,30,0\\r\\n8,110,76,0,0,27.8,0.237,58,0\\r\\n11,103,68,40,0,46.2,0.126,42,0\\r\\n11,85,74,0,0,30.1,0.3,35,0\\r\\n6,125,76,0,0,33.8,0.121,54,1\\r\\n0,198,66,32,274,41.3,0.502,28,1\\r\\n1,87,68,34,77,37.6,0.401,24,0\\r\\n6,99,60,19,54,26.9,0.497,32,0\\r\\n0,91,80,0,0,32.4,0.601,27,0\\r\\n2,95,54,14,88,26.1,0.748,22,0\\r\\n1,99,72,30,18,38.6,0.412,21,0\\r\\n6,92,62,32,126,32,0.085,46,0\\r\\n4,154,72,29,126,31.3,0.338,37,0\\r\\n0,121,66,30,165,34.3,0.203,33,1\\r\\n3,78,70,0,0,32.5,0.27,39,0\\r\\n2,130,96,0,0,22.6,0.268,21,0\\r\\n3,111,58,31,44,29.5,0.43,22,0\\r\\n2,98,60,17,120,34.7,0.198,22,0\\r\\n1,143,86,30,330,30.1,0.892,23,0\\r\\n1,119,44,47,63,35.5,0.28,25,0\\r\\n6,108,44,20,130,24,0.813,35,0\\r\\n2,118,80,0,0,42.9,0.693,21,1\\r\\n10,133,68,0,0,27,0.245,36,0\\r\\n2,197,70,99,0,34.7,0.575,62,1\\r\\n0,151,90,46,0,42.1,0.371,21,1\\r\\n6,109,60,27,0,25,0.206,27,0\\r\\n12,121,78,17,0,26.5,0.259,62,0\\r\\n8,100,76,0,0,38.7,0.19,42,0\\r\\n8,124,76,24,600,28.7,0.687,52,1\\r\\n1,93,56,11,0,22.5,0.417,22,0\\r\\n8,143,66,0,0,34.9,0.129,41,1\\r\\n6,103,66,0,0,24.3,0.249,29,0\\r\\n3,176,86,27,156,33.3,1.154,52,1\\r\\n0,73,0,0,0,21.1,0.342,25,0\\r\\n11,111,84,40,0,46.8,0.925,45,1\\r\\n2,112,78,50,140,39.4,0.175,24,0\\r\\n3,132,80,0,0,34.4,0.402,44,1\\r\\n2,82,52,22,115,28.5,1.699,25,0\\r\\n6,123,72,45,230,33.6,0.733,34,0\\r\\n0,188,82,14,185,32,0.682,22,1\\r\\n0,67,76,0,0,45.3,0.194,46,0\\r\\n1,89,24,19,25,27.8,0.559,21,0\\r\\n1,173,74,0,0,36.8,0.088,38,1\\r\\n1,109,38,18,120,23.1,0.407,26,0\\r\\n1,108,88,19,0,27.1,0.4,24,0\\r\\n6,96,0,0,0,23.7,0.19,28,0\\r\\n1,124,74,36,0,27.8,0.1,30,0\\r\\n7,150,78,29,126,35.2,0.692,54,1\\r\\n4,183,0,0,0,28.4,0.212,36,1\\r\\n1,124,60,32,0,35.8,0.514,21,0\\r\\n1,181,78,42,293,40,1.258,22,1\\r\\n1,92,62,25,41,19.5,0.482,25,0\\r\\n0,152,82,39,272,41.5,0.27,27,0\\r\\n1,111,62,13,182,24,0.138,23,0\\r\\n3,106,54,21,158,30.9,0.292,24,0\\r\\n3,174,58,22,194,32.9,0.593,36,1\\r\\n7,168,88,42,321,38.2,0.787,40,1\\r\\n6,105,80,28,0,32.5,0.878,26,0\\r\\n11,138,74,26,144,36.1,0.557,50,1\\r\\n3,106,72,0,0,25.8,0.207,27,0\\r\\n6,117,96,0,0,28.7,0.157,30,0\\r\\n2,68,62,13,15,20.1,0.257,23,0\\r\\n9,112,82,24,0,28.2,1.282,50,1\\r\\n0,119,0,0,0,32.4,0.141,24,1\\r\\n2,112,86,42,160,38.4,0.246,28,0\\r\\n2,92,76,20,0,24.2,1.698,28,0\\r\\n6,183,94,0,0,40.8,1.461,45,0\\r\\n0,94,70,27,115,43.5,0.347,21,0\\r\\n2,108,64,0,0,30.8,0.158,21,0\\r\\n4,90,88,47,54,37.7,0.362,29,0\\r\\n0,125,68,0,0,24.7,0.206,21,0\\r\\n0,132,78,0,0,32.4,0.393,21,0\\r\\n5,128,80,0,0,34.6,0.144,45,0\\r\\n4,94,65,22,0,24.7,0.148,21,0\\r\\n7,114,64,0,0,27.4,0.732,34,1\\r\\n0,102,78,40,90,34.5,0.238,24,0\\r\\n2,111,60,0,0,26.2,0.343,23,0\\r\\n1,128,82,17,183,27.5,0.115,22,0\\r\\n10,92,62,0,0,25.9,0.167,31,0\\r\\n13,104,72,0,0,31.2,0.465,38,1\\r\\n5,104,74,0,0,28.8,0.153,48,0\\r\\n2,94,76,18,66,31.6,0.649,23,0\\r\\n7,97,76,32,91,40.9,0.871,32,1\\r\\n1,100,74,12,46,19.5,0.149,28,0\\r\\n0,102,86,17,105,29.3,0.695,27,0\\r\\n4,128,70,0,0,34.3,0.303,24,0\\r\\n6,147,80,0,0,29.5,0.178,50,1\\r\\n4,90,0,0,0,28,0.61,31,0\\r\\n3,103,72,30,152,27.6,0.73,27,0\\r\\n2,157,74,35,440,39.4,0.134,30,0\\r\\n1,167,74,17,144,23.4,0.447,33,1\\r\\n0,179,50,36,159,37.8,0.455,22,1\\r\\n11,136,84,35,130,28.3,0.26,42,1\\r\\n0,107,60,25,0,26.4,0.133,23,0\\r\\n1,91,54,25,100,25.2,0.234,23,0\\r\\n1,117,60,23,106,33.8,0.466,27,0\\r\\n5,123,74,40,77,34.1,0.269,28,0\\r\\n2,120,54,0,0,26.8,0.455,27,0\\r\\n1,106,70,28,135,34.2,0.142,22,0\\r\\n2,155,52,27,540,38.7,0.24,25,1\\r\\n2,101,58,35,90,21.8,0.155,22,0\\r\\n1,120,80,48,200,38.9,1.162,41,0\\r\\n11,127,106,0,0,39,0.19,51,0\\r\\n3,80,82,31,70,34.2,1.292,27,1\\r\\n10,162,84,0,0,27.7,0.182,54,0\\r\\n1,199,76,43,0,42.9,1.394,22,1\\r\\n8,167,106,46,231,37.6,0.165,43,1\\r\\n9,145,80,46,130,37.9,0.637,40,1\\r\\n6,115,60,39,0,33.7,0.245,40,1\\r\\n1,112,80,45,132,34.8,0.217,24,0\\r\\n4,145,82,18,0,32.5,0.235,70,1\\r\\n10,111,70,27,0,27.5,0.141,40,1\\r\\n6,98,58,33,190,34,0.43,43,0\\r\\n9,154,78,30,100,30.9,0.164,45,0\\r\\n6,165,68,26,168,33.6,0.631,49,0\\r\\n1,99,58,10,0,25.4,0.551,21,0\\r\\n10,68,106,23,49,35.5,0.285,47,0\\r\\n3,123,100,35,240,57.3,0.88,22,0\\r\\n8,91,82,0,0,35.6,0.587,68,0\\r\\n6,195,70,0,0,30.9,0.328,31,1\\r\\n9,156,86,0,0,24.8,0.23,53,1\\r\\n0,93,60,0,0,35.3,0.263,25,0\\r\\n3,121,52,0,0,36,0.127,25,1\\r\\n2,101,58,17,265,24.2,0.614,23,0\\r\\n2,56,56,28,45,24.2,0.332,22,0\\r\\n0,162,76,36,0,49.6,0.364,26,1\\r\\n0,95,64,39,105,44.6,0.366,22,0\\r\\n4,125,80,0,0,32.3,0.536,27,1\\r\\n5,136,82,0,0,0,0.64,69,0\\r\\n2,129,74,26,205,33.2,0.591,25,0\\r\\n3,130,64,0,0,23.1,0.314,22,0\\r\\n1,107,50,19,0,28.3,0.181,29,0\\r\\n1,140,74,26,180,24.1,0.828,23,0\\r\\n1,144,82,46,180,46.1,0.335,46,1\\r\\n8,107,80,0,0,24.6,0.856,34,0\\r\\n13,158,114,0,0,42.3,0.257,44,1\\r\\n2,121,70,32,95,39.1,0.886,23,0\\r\\n7,129,68,49,125,38.5,0.439,43,1\\r\\n2,90,60,0,0,23.5,0.191,25,0\\r\\n7,142,90,24,480,30.4,0.128,43,1\\r\\n3,169,74,19,125,29.9,0.268,31,1\\r\\n0,99,0,0,0,25,0.253,22,0\\r\\n4,127,88,11,155,34.5,0.598,28,0\\r\\n4,118,70,0,0,44.5,0.904,26,0\\r\\n2,122,76,27,200,35.9,0.483,26,0\\r\\n6,125,78,31,0,27.6,0.565,49,1\\r\\n1,168,88,29,0,35,0.905,52,1\\r\\n2,129,0,0,0,38.5,0.304,41,0\\r\\n4,110,76,20,100,28.4,0.118,27,0\\r\\n6,80,80,36,0,39.8,0.177,28,0\\r\\n10,115,0,0,0,0,0.261,30,1\\r\\n2,127,46,21,335,34.4,0.176,22,0\\r\\n9,164,78,0,0,32.8,0.148,45,1\\r\\n2,93,64,32,160,38,0.674,23,1\\r\\n3,158,64,13,387,31.2,0.295,24,0\\r\\n5,126,78,27,22,29.6,0.439,40,0\\r\\n10,129,62,36,0,41.2,0.441,38,1\\r\\n0,134,58,20,291,26.4,0.352,21,0\\r\\n3,102,74,0,0,29.5,0.121,32,0\\r\\n7,187,50,33,392,33.9,0.826,34,1\\r\\n3,173,78,39,185,33.8,0.97,31,1\\r\\n10,94,72,18,0,23.1,0.595,56,0\\r\\n1,108,60,46,178,35.5,0.415,24,0\\r\\n5,97,76,27,0,35.6,0.378,52,1\\r\\n4,83,86,19,0,29.3,0.317,34,0\\r\\n1,114,66,36,200,38.1,0.289,21,0\\r\\n1,149,68,29,127,29.3,0.349,42,1\\r\\n5,117,86,30,105,39.1,0.251,42,0\\r\\n1,111,94,0,0,32.8,0.265,45,0\\r\\n4,112,78,40,0,39.4,0.236,38,0\\r\\n1,116,78,29,180,36.1,0.496,25,0\\r\\n0,141,84,26,0,32.4,0.433,22,0\\r\\n2,175,88,0,0,22.9,0.326,22,0\\r\\n2,92,52,0,0,30.1,0.141,22,0\\r\\n3,130,78,23,79,28.4,0.323,34,1\\r\\n8,120,86,0,0,28.4,0.259,22,1\\r\\n2,174,88,37,120,44.5,0.646,24,1\\r\\n2,106,56,27,165,29,0.426,22,0\\r\\n2,105,75,0,0,23.3,0.56,53,0\\r\\n4,95,60,32,0,35.4,0.284,28,0\\r\\n0,126,86,27,120,27.4,0.515,21,0\\r\\n8,65,72,23,0,32,0.6,42,0\\r\\n2,99,60,17,160,36.6,0.453,21,0\\r\\n1,102,74,0,0,39.5,0.293,42,1\\r\\n11,120,80,37,150,42.3,0.785,48,1\\r\\n3,102,44,20,94,30.8,0.4,26,0\\r\\n1,109,58,18,116,28.5,0.219,22,0\\r\\n9,140,94,0,0,32.7,0.734,45,1\\r\\n13,153,88,37,140,40.6,1.174,39,0\\r\\n12,100,84,33,105,30,0.488,46,0\\r\\n1,147,94,41,0,49.3,0.358,27,1\\r\\n1,81,74,41,57,46.3,1.096,32,0\\r\\n3,187,70,22,200,36.4,0.408,36,1\\r\\n6,162,62,0,0,24.3,0.178,50,1\\r\\n4,136,70,0,0,31.2,1.182,22,1\\r\\n1,121,78,39,74,39,0.261,28,0\\r\\n3,108,62,24,0,26,0.223,25,0\\r\\n0,181,88,44,510,43.3,0.222,26,1\\r\\n8,154,78,32,0,32.4,0.443,45,1\\r\\n1,128,88,39,110,36.5,1.057,37,1\\r\\n7,137,90,41,0,32,0.391,39,0\\r\\n0,123,72,0,0,36.3,0.258,52,1\\r\\n1,106,76,0,0,37.5,0.197,26,0\\r\\n6,190,92,0,0,35.5,0.278,66,1\\r\\n2,88,58,26,16,28.4,0.766,22,0\\r\\n9,170,74,31,0,44,0.403,43,1\\r\\n9,89,62,0,0,22.5,0.142,33,0\\r\\n10,101,76,48,180,32.9,0.171,63,0\\r\\n2,122,70,27,0,36.8,0.34,27,0\\r\\n5,121,72,23,112,26.2,0.245,30,0\\r\\n1,126,60,0,0,30.1,0.349,47,1\\r\\n1,93,70,31,0,30.4,0.315,23,0'}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Acomodando los datos"
      ],
      "metadata": {
        "id": "z_h97LkoOmqJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAoSZ4sQHydu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "277e7c26-abe7-40a0-b266-1ea8e7abd5e6"
      },
      "source": [
        "# Leyendo los datos separados por comas y convirtiendo en numpy\n",
        "df = pd.read_csv('diabetes.csv')\n",
        "data= df.to_numpy()\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0              6      148             72             35        0  33.6   \n",
              "1              1       85             66             29        0  26.6   \n",
              "2              8      183             64              0        0  23.3   \n",
              "3              1       89             66             23       94  28.1   \n",
              "4              0      137             40             35      168  43.1   \n",
              "..           ...      ...            ...            ...      ...   ...   \n",
              "763           10      101             76             48      180  32.9   \n",
              "764            2      122             70             27        0  36.8   \n",
              "765            5      121             72             23      112  26.2   \n",
              "766            1      126             60              0        0  30.1   \n",
              "767            1       93             70             31        0  30.4   \n",
              "\n",
              "     DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                       0.627   50        1  \n",
              "1                       0.351   31        0  \n",
              "2                       0.672   32        1  \n",
              "3                       0.167   21        0  \n",
              "4                       2.288   33        1  \n",
              "..                        ...  ...      ...  \n",
              "763                     0.171   63        0  \n",
              "764                     0.340   27        0  \n",
              "765                     0.245   30        0  \n",
              "766                     0.349   47        1  \n",
              "767                     0.315   23        0  \n",
              "\n",
              "[768 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-653280d2-0c2c-4142-baec-767befc028e8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10</td>\n",
              "      <td>101</td>\n",
              "      <td>76</td>\n",
              "      <td>48</td>\n",
              "      <td>180</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5</td>\n",
              "      <td>121</td>\n",
              "      <td>72</td>\n",
              "      <td>23</td>\n",
              "      <td>112</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>70</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-653280d2-0c2c-4142-baec-767befc028e8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-653280d2-0c2c-4142-baec-767befc028e8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-653280d2-0c2c-4142-baec-767befc028e8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dQ6sMAuIfji"
      },
      "source": [
        "# Se dividen los datos en entrenamiento y validación\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop('Outcome' , axis = 1)\n",
        "Y = df['Outcome']\n",
        "\n",
        "\n",
        "X_ent, X_val, Y_ent, Y_val = train_test_split(X, Y, test_size =0.1, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generando el modelo con Tensorflow"
      ],
      "metadata": {
        "id": "y08cQInbRy9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Entrada: Capa Input con el número de características de los datos\n",
        "#Salidas: Capa Totalmente conectada (Dense) con el número de neuronas\n",
        "#         igual a la cantidad de salidas que deseamos\n",
        "\n",
        "input_dt= tf.keras.layers.Input(shape= (8))\n",
        "x= tf.keras.layers.Dense(8, 'relu')(input_dt)\n",
        "x= tf.keras.layers.Dense(16, 'relu')(x)\n",
        "x= tf.keras.layers.Dense(16, 'relu')(x)\n",
        "salida= tf.keras.layers.Dense(1, 'sigmoid')(x)\n",
        "\n",
        "# Defininmos el modelo con la capa de entrada y salida\n",
        "model= tf.keras.Model(inputs= input_dt, outputs= salida)\n",
        "\n",
        "# Resumimos el modelo para verificar que sea la arquitectura deseada\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# Compilación del modelo;\n",
        "#   Optimizador: Adam\n",
        "#   Loss: Binary crossentropy\n",
        "#   Epocas: Número de veces que se va a entrenar el modelo\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(), loss = 'binary_crossentropy', metrics= ['accuracy'])\n",
        "history= model.fit(X_ent, Y_ent, validation_data= [X_val, Y_val], epochs= 1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEHvGbLiWQSj",
        "outputId": "859f945e-4369-4a54-ada6-8f31aca76bb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 8)]               0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 16)                144       \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 16)                272       \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 505\n",
            "Trainable params: 505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1000\n",
            "22/22 [==============================] - 1s 16ms/step - loss: 7.2025 - accuracy: 0.6469 - val_loss: 2.1399 - val_accuracy: 0.6494\n",
            "Epoch 2/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 1.4460 - accuracy: 0.4747 - val_loss: 0.9148 - val_accuracy: 0.6234\n",
            "Epoch 3/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.8122 - accuracy: 0.6006 - val_loss: 0.6828 - val_accuracy: 0.6623\n",
            "Epoch 4/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.7487 - accuracy: 0.6397 - val_loss: 0.6350 - val_accuracy: 0.6364\n",
            "Epoch 5/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.6978 - accuracy: 0.6208 - val_loss: 0.6011 - val_accuracy: 0.6753\n",
            "Epoch 6/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.6572 - accuracy: 0.6107 - val_loss: 0.6231 - val_accuracy: 0.6623\n",
            "Epoch 7/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.6687 - accuracy: 0.6368 - val_loss: 0.6005 - val_accuracy: 0.6623\n",
            "Epoch 8/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.6358 - accuracy: 0.6512 - val_loss: 0.6324 - val_accuracy: 0.6883\n",
            "Epoch 9/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.6306 - accuracy: 0.6295 - val_loss: 0.5952 - val_accuracy: 0.6753\n",
            "Epoch 10/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.6312 - accuracy: 0.6483 - val_loss: 0.6067 - val_accuracy: 0.6753\n",
            "Epoch 11/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.6230 - accuracy: 0.6614 - val_loss: 0.5887 - val_accuracy: 0.6623\n",
            "Epoch 12/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.6258 - accuracy: 0.6527 - val_loss: 0.5947 - val_accuracy: 0.6234\n",
            "Epoch 13/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.6273 - accuracy: 0.6599 - val_loss: 0.6081 - val_accuracy: 0.5455\n",
            "Epoch 14/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.6289 - accuracy: 0.6382 - val_loss: 0.6307 - val_accuracy: 0.5844\n",
            "Epoch 15/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.6372 - accuracy: 0.6440 - val_loss: 0.6064 - val_accuracy: 0.6623\n",
            "Epoch 16/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.6139 - accuracy: 0.6845 - val_loss: 0.5988 - val_accuracy: 0.6364\n",
            "Epoch 17/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.6141 - accuracy: 0.6758 - val_loss: 0.6379 - val_accuracy: 0.6753\n",
            "Epoch 18/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.6478 - accuracy: 0.6324 - val_loss: 0.6135 - val_accuracy: 0.6623\n",
            "Epoch 19/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.6073 - accuracy: 0.6585 - val_loss: 0.6161 - val_accuracy: 0.5714\n",
            "Epoch 20/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.6095 - accuracy: 0.6787 - val_loss: 0.6007 - val_accuracy: 0.5974\n",
            "Epoch 21/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5985 - accuracy: 0.6816 - val_loss: 0.6411 - val_accuracy: 0.6494\n",
            "Epoch 22/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.6125 - accuracy: 0.6845 - val_loss: 0.6073 - val_accuracy: 0.5455\n",
            "Epoch 23/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.6184 - accuracy: 0.6541 - val_loss: 0.6027 - val_accuracy: 0.6494\n",
            "Epoch 24/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.6011 - accuracy: 0.6845 - val_loss: 0.6167 - val_accuracy: 0.5974\n",
            "Epoch 25/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.6073 - accuracy: 0.6889 - val_loss: 0.6006 - val_accuracy: 0.6623\n",
            "Epoch 26/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5868 - accuracy: 0.7033 - val_loss: 0.6224 - val_accuracy: 0.5844\n",
            "Epoch 27/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5892 - accuracy: 0.7004 - val_loss: 0.6491 - val_accuracy: 0.6623\n",
            "Epoch 28/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5984 - accuracy: 0.6787 - val_loss: 0.6232 - val_accuracy: 0.6104\n",
            "Epoch 29/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5939 - accuracy: 0.6700 - val_loss: 0.5944 - val_accuracy: 0.7143\n",
            "Epoch 30/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5931 - accuracy: 0.6802 - val_loss: 0.6019 - val_accuracy: 0.6494\n",
            "Epoch 31/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5945 - accuracy: 0.6860 - val_loss: 0.6353 - val_accuracy: 0.6623\n",
            "Epoch 32/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5998 - accuracy: 0.6946 - val_loss: 0.6191 - val_accuracy: 0.6883\n",
            "Epoch 33/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.6079 - accuracy: 0.6773 - val_loss: 0.5981 - val_accuracy: 0.6623\n",
            "Epoch 34/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5855 - accuracy: 0.6889 - val_loss: 0.6040 - val_accuracy: 0.6364\n",
            "Epoch 35/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5987 - accuracy: 0.6643 - val_loss: 0.5960 - val_accuracy: 0.7273\n",
            "Epoch 36/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5980 - accuracy: 0.7019 - val_loss: 0.6279 - val_accuracy: 0.6753\n",
            "Epoch 37/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5758 - accuracy: 0.7033 - val_loss: 0.5984 - val_accuracy: 0.7143\n",
            "Epoch 38/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5677 - accuracy: 0.6961 - val_loss: 0.5881 - val_accuracy: 0.6883\n",
            "Epoch 39/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5708 - accuracy: 0.6932 - val_loss: 0.5992 - val_accuracy: 0.6494\n",
            "Epoch 40/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5630 - accuracy: 0.7135 - val_loss: 0.5831 - val_accuracy: 0.6753\n",
            "Epoch 41/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5707 - accuracy: 0.7106 - val_loss: 0.6046 - val_accuracy: 0.6883\n",
            "Epoch 42/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5818 - accuracy: 0.6990 - val_loss: 0.5871 - val_accuracy: 0.7143\n",
            "Epoch 43/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5786 - accuracy: 0.6860 - val_loss: 0.5854 - val_accuracy: 0.7143\n",
            "Epoch 44/1000\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.5603 - accuracy: 0.7149 - val_loss: 0.6193 - val_accuracy: 0.6364\n",
            "Epoch 45/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5593 - accuracy: 0.7135 - val_loss: 0.5826 - val_accuracy: 0.7273\n",
            "Epoch 46/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5636 - accuracy: 0.7164 - val_loss: 0.5841 - val_accuracy: 0.7013\n",
            "Epoch 47/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5622 - accuracy: 0.7062 - val_loss: 0.6553 - val_accuracy: 0.6234\n",
            "Epoch 48/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5779 - accuracy: 0.6946 - val_loss: 0.6636 - val_accuracy: 0.5974\n",
            "Epoch 49/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5687 - accuracy: 0.6990 - val_loss: 0.6031 - val_accuracy: 0.6883\n",
            "Epoch 50/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5594 - accuracy: 0.7062 - val_loss: 0.5886 - val_accuracy: 0.7013\n",
            "Epoch 51/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5668 - accuracy: 0.7019 - val_loss: 0.6402 - val_accuracy: 0.6234\n",
            "Epoch 52/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5618 - accuracy: 0.7019 - val_loss: 0.5870 - val_accuracy: 0.7273\n",
            "Epoch 53/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5774 - accuracy: 0.7192 - val_loss: 0.5849 - val_accuracy: 0.6883\n",
            "Epoch 54/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5772 - accuracy: 0.6975 - val_loss: 0.5960 - val_accuracy: 0.6623\n",
            "Epoch 55/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5808 - accuracy: 0.7091 - val_loss: 0.6318 - val_accuracy: 0.6753\n",
            "Epoch 56/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5666 - accuracy: 0.7192 - val_loss: 0.5967 - val_accuracy: 0.7143\n",
            "Epoch 57/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5853 - accuracy: 0.6787 - val_loss: 0.5865 - val_accuracy: 0.6883\n",
            "Epoch 58/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5712 - accuracy: 0.6860 - val_loss: 0.5924 - val_accuracy: 0.6883\n",
            "Epoch 59/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5656 - accuracy: 0.7048 - val_loss: 0.5813 - val_accuracy: 0.6753\n",
            "Epoch 60/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5593 - accuracy: 0.7135 - val_loss: 0.5802 - val_accuracy: 0.6883\n",
            "Epoch 61/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5461 - accuracy: 0.7207 - val_loss: 0.5769 - val_accuracy: 0.7273\n",
            "Epoch 62/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5763 - accuracy: 0.7221 - val_loss: 0.6233 - val_accuracy: 0.6623\n",
            "Epoch 63/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5674 - accuracy: 0.6961 - val_loss: 0.5823 - val_accuracy: 0.6753\n",
            "Epoch 64/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5612 - accuracy: 0.6961 - val_loss: 0.5821 - val_accuracy: 0.7013\n",
            "Epoch 65/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5668 - accuracy: 0.7106 - val_loss: 0.6259 - val_accuracy: 0.6364\n",
            "Epoch 66/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5681 - accuracy: 0.7004 - val_loss: 0.5828 - val_accuracy: 0.7143\n",
            "Epoch 67/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5686 - accuracy: 0.7048 - val_loss: 0.5851 - val_accuracy: 0.7013\n",
            "Epoch 68/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5548 - accuracy: 0.7178 - val_loss: 0.6291 - val_accuracy: 0.6494\n",
            "Epoch 69/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5458 - accuracy: 0.7221 - val_loss: 0.5850 - val_accuracy: 0.7013\n",
            "Epoch 70/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5425 - accuracy: 0.7192 - val_loss: 0.5856 - val_accuracy: 0.7143\n",
            "Epoch 71/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5386 - accuracy: 0.7221 - val_loss: 0.5736 - val_accuracy: 0.7143\n",
            "Epoch 72/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5413 - accuracy: 0.7135 - val_loss: 0.5793 - val_accuracy: 0.6883\n",
            "Epoch 73/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5409 - accuracy: 0.7279 - val_loss: 0.5746 - val_accuracy: 0.7273\n",
            "Epoch 74/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5357 - accuracy: 0.7294 - val_loss: 0.5609 - val_accuracy: 0.7532\n",
            "Epoch 75/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5447 - accuracy: 0.7207 - val_loss: 0.5785 - val_accuracy: 0.7403\n",
            "Epoch 76/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5667 - accuracy: 0.7048 - val_loss: 0.5838 - val_accuracy: 0.6753\n",
            "Epoch 77/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5584 - accuracy: 0.7164 - val_loss: 0.6508 - val_accuracy: 0.6234\n",
            "Epoch 78/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5423 - accuracy: 0.7192 - val_loss: 0.5899 - val_accuracy: 0.7273\n",
            "Epoch 79/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5335 - accuracy: 0.7323 - val_loss: 0.5827 - val_accuracy: 0.7403\n",
            "Epoch 80/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5428 - accuracy: 0.7149 - val_loss: 0.5899 - val_accuracy: 0.7013\n",
            "Epoch 81/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5531 - accuracy: 0.7192 - val_loss: 0.5977 - val_accuracy: 0.7273\n",
            "Epoch 82/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.6918 - val_loss: 0.5716 - val_accuracy: 0.7273\n",
            "Epoch 83/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5730 - accuracy: 0.7178 - val_loss: 0.5610 - val_accuracy: 0.7273\n",
            "Epoch 84/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.7352 - val_loss: 0.5728 - val_accuracy: 0.7273\n",
            "Epoch 85/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5279 - accuracy: 0.7207 - val_loss: 0.5733 - val_accuracy: 0.7532\n",
            "Epoch 86/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5437 - accuracy: 0.7033 - val_loss: 0.5714 - val_accuracy: 0.7403\n",
            "Epoch 87/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5349 - accuracy: 0.7308 - val_loss: 0.5968 - val_accuracy: 0.6883\n",
            "Epoch 88/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5428 - accuracy: 0.7279 - val_loss: 0.5623 - val_accuracy: 0.7273\n",
            "Epoch 89/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5508 - accuracy: 0.7120 - val_loss: 0.6138 - val_accuracy: 0.6623\n",
            "Epoch 90/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5386 - accuracy: 0.7294 - val_loss: 0.5662 - val_accuracy: 0.7143\n",
            "Epoch 91/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.7438 - val_loss: 0.5716 - val_accuracy: 0.7662\n",
            "Epoch 92/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.7424 - val_loss: 0.5836 - val_accuracy: 0.6623\n",
            "Epoch 93/1000\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.7279 - val_loss: 0.6304 - val_accuracy: 0.6753\n",
            "Epoch 94/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5688 - accuracy: 0.6990 - val_loss: 0.6370 - val_accuracy: 0.7143\n",
            "Epoch 95/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.7352 - val_loss: 0.5587 - val_accuracy: 0.7273\n",
            "Epoch 96/1000\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.7366 - val_loss: 0.5747 - val_accuracy: 0.6883\n",
            "Epoch 97/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5438 - accuracy: 0.7236 - val_loss: 0.5818 - val_accuracy: 0.7273\n",
            "Epoch 98/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.7323 - val_loss: 0.5676 - val_accuracy: 0.7143\n",
            "Epoch 99/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5338 - accuracy: 0.7337 - val_loss: 0.5896 - val_accuracy: 0.7013\n",
            "Epoch 100/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5281 - accuracy: 0.7178 - val_loss: 0.5692 - val_accuracy: 0.7013\n",
            "Epoch 101/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5296 - accuracy: 0.7207 - val_loss: 0.5731 - val_accuracy: 0.7403\n",
            "Epoch 102/1000\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.7236 - val_loss: 0.5791 - val_accuracy: 0.7403\n",
            "Epoch 103/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5281 - accuracy: 0.7236 - val_loss: 0.5685 - val_accuracy: 0.7273\n",
            "Epoch 104/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5390 - accuracy: 0.7337 - val_loss: 0.6141 - val_accuracy: 0.6623\n",
            "Epoch 105/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5354 - accuracy: 0.7236 - val_loss: 0.5870 - val_accuracy: 0.6753\n",
            "Epoch 106/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5282 - accuracy: 0.7352 - val_loss: 0.5695 - val_accuracy: 0.7273\n",
            "Epoch 107/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5263 - accuracy: 0.7395 - val_loss: 0.5640 - val_accuracy: 0.7273\n",
            "Epoch 108/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5246 - accuracy: 0.7352 - val_loss: 0.5645 - val_accuracy: 0.7403\n",
            "Epoch 109/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5320 - accuracy: 0.7279 - val_loss: 0.5698 - val_accuracy: 0.6883\n",
            "Epoch 110/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5529 - accuracy: 0.7250 - val_loss: 0.5832 - val_accuracy: 0.6623\n",
            "Epoch 111/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5477 - accuracy: 0.7352 - val_loss: 0.5604 - val_accuracy: 0.7273\n",
            "Epoch 112/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5455 - accuracy: 0.7279 - val_loss: 0.5874 - val_accuracy: 0.7143\n",
            "Epoch 113/1000\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.7308 - val_loss: 0.5559 - val_accuracy: 0.7273\n",
            "Epoch 114/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7352 - val_loss: 0.5653 - val_accuracy: 0.7013\n",
            "Epoch 115/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7410 - val_loss: 0.5587 - val_accuracy: 0.7143\n",
            "Epoch 116/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7323 - val_loss: 0.5871 - val_accuracy: 0.7143\n",
            "Epoch 117/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.7337 - val_loss: 0.5760 - val_accuracy: 0.6883\n",
            "Epoch 118/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5191 - accuracy: 0.7221 - val_loss: 0.5657 - val_accuracy: 0.7403\n",
            "Epoch 119/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7554 - val_loss: 0.5728 - val_accuracy: 0.6883\n",
            "Epoch 120/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.7482 - val_loss: 0.5868 - val_accuracy: 0.6753\n",
            "Epoch 121/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5149 - accuracy: 0.7438 - val_loss: 0.5665 - val_accuracy: 0.7143\n",
            "Epoch 122/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5374 - accuracy: 0.7410 - val_loss: 0.5589 - val_accuracy: 0.7143\n",
            "Epoch 123/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7438 - val_loss: 0.5675 - val_accuracy: 0.7532\n",
            "Epoch 124/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5241 - accuracy: 0.7265 - val_loss: 0.5938 - val_accuracy: 0.7013\n",
            "Epoch 125/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7482 - val_loss: 0.5603 - val_accuracy: 0.7143\n",
            "Epoch 126/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5272 - accuracy: 0.7279 - val_loss: 0.5685 - val_accuracy: 0.7662\n",
            "Epoch 127/1000\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7366 - val_loss: 0.5674 - val_accuracy: 0.7273\n",
            "Epoch 128/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5219 - accuracy: 0.7308 - val_loss: 0.5901 - val_accuracy: 0.7273\n",
            "Epoch 129/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7395 - val_loss: 0.5750 - val_accuracy: 0.7143\n",
            "Epoch 130/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5346 - accuracy: 0.7192 - val_loss: 0.5842 - val_accuracy: 0.6883\n",
            "Epoch 131/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5242 - accuracy: 0.7308 - val_loss: 0.5900 - val_accuracy: 0.7273\n",
            "Epoch 132/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5157 - accuracy: 0.7641 - val_loss: 0.5871 - val_accuracy: 0.6753\n",
            "Epoch 133/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5164 - accuracy: 0.7381 - val_loss: 0.5601 - val_accuracy: 0.7532\n",
            "Epoch 134/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7352 - val_loss: 0.5737 - val_accuracy: 0.7273\n",
            "Epoch 135/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7381 - val_loss: 0.5627 - val_accuracy: 0.7143\n",
            "Epoch 136/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7453 - val_loss: 0.6041 - val_accuracy: 0.7273\n",
            "Epoch 137/1000\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7395 - val_loss: 0.5781 - val_accuracy: 0.7273\n",
            "Epoch 138/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5002 - accuracy: 0.7583 - val_loss: 0.5775 - val_accuracy: 0.6883\n",
            "Epoch 139/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7453 - val_loss: 0.5716 - val_accuracy: 0.7273\n",
            "Epoch 140/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.7467 - val_loss: 0.5808 - val_accuracy: 0.7013\n",
            "Epoch 141/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7366 - val_loss: 0.5618 - val_accuracy: 0.7273\n",
            "Epoch 142/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5036 - accuracy: 0.7583 - val_loss: 0.5666 - val_accuracy: 0.7143\n",
            "Epoch 143/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5031 - accuracy: 0.7656 - val_loss: 0.5623 - val_accuracy: 0.7273\n",
            "Epoch 144/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5258 - accuracy: 0.7352 - val_loss: 0.6422 - val_accuracy: 0.6883\n",
            "Epoch 145/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7583 - val_loss: 0.5854 - val_accuracy: 0.7013\n",
            "Epoch 146/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4970 - accuracy: 0.7583 - val_loss: 0.5611 - val_accuracy: 0.7532\n",
            "Epoch 147/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4869 - accuracy: 0.7757 - val_loss: 0.5709 - val_accuracy: 0.7013\n",
            "Epoch 148/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7540 - val_loss: 0.5865 - val_accuracy: 0.7273\n",
            "Epoch 149/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5011 - accuracy: 0.7699 - val_loss: 0.5706 - val_accuracy: 0.7013\n",
            "Epoch 150/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4970 - accuracy: 0.7583 - val_loss: 0.5754 - val_accuracy: 0.7273\n",
            "Epoch 151/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5002 - accuracy: 0.7438 - val_loss: 0.5638 - val_accuracy: 0.7273\n",
            "Epoch 152/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.7453 - val_loss: 0.5722 - val_accuracy: 0.7143\n",
            "Epoch 153/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4983 - accuracy: 0.7685 - val_loss: 0.5526 - val_accuracy: 0.7532\n",
            "Epoch 154/1000\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.7337 - val_loss: 0.5687 - val_accuracy: 0.7013\n",
            "Epoch 155/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4981 - accuracy: 0.7627 - val_loss: 0.5581 - val_accuracy: 0.7403\n",
            "Epoch 156/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5014 - accuracy: 0.7511 - val_loss: 0.5507 - val_accuracy: 0.7532\n",
            "Epoch 157/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.7641 - val_loss: 0.5552 - val_accuracy: 0.7403\n",
            "Epoch 158/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4882 - accuracy: 0.7569 - val_loss: 0.5552 - val_accuracy: 0.7532\n",
            "Epoch 159/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4894 - accuracy: 0.7554 - val_loss: 0.5567 - val_accuracy: 0.7403\n",
            "Epoch 160/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4958 - accuracy: 0.7713 - val_loss: 0.5673 - val_accuracy: 0.7403\n",
            "Epoch 161/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 0.7554 - val_loss: 0.5701 - val_accuracy: 0.7403\n",
            "Epoch 162/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.7728 - val_loss: 0.5526 - val_accuracy: 0.7403\n",
            "Epoch 163/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4994 - accuracy: 0.7583 - val_loss: 0.5580 - val_accuracy: 0.7013\n",
            "Epoch 164/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4997 - accuracy: 0.7771 - val_loss: 0.5596 - val_accuracy: 0.7013\n",
            "Epoch 165/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4931 - accuracy: 0.7554 - val_loss: 0.6156 - val_accuracy: 0.7273\n",
            "Epoch 166/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.7352 - val_loss: 0.5684 - val_accuracy: 0.7013\n",
            "Epoch 167/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4903 - accuracy: 0.7554 - val_loss: 0.5545 - val_accuracy: 0.7273\n",
            "Epoch 168/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4954 - accuracy: 0.7482 - val_loss: 0.5497 - val_accuracy: 0.7403\n",
            "Epoch 169/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4963 - accuracy: 0.7496 - val_loss: 0.5593 - val_accuracy: 0.7143\n",
            "Epoch 170/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.7540 - val_loss: 0.5668 - val_accuracy: 0.7013\n",
            "Epoch 171/1000\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7482 - val_loss: 0.5940 - val_accuracy: 0.7273\n",
            "Epoch 172/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.7410 - val_loss: 0.5483 - val_accuracy: 0.7662\n",
            "Epoch 173/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4824 - accuracy: 0.7612 - val_loss: 0.5493 - val_accuracy: 0.7403\n",
            "Epoch 174/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.7540 - val_loss: 0.5489 - val_accuracy: 0.7662\n",
            "Epoch 175/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4889 - accuracy: 0.7540 - val_loss: 0.5469 - val_accuracy: 0.7403\n",
            "Epoch 176/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 0.7670 - val_loss: 0.5659 - val_accuracy: 0.7403\n",
            "Epoch 177/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.7844 - val_loss: 0.5551 - val_accuracy: 0.7143\n",
            "Epoch 178/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7395 - val_loss: 0.6164 - val_accuracy: 0.7403\n",
            "Epoch 179/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4997 - accuracy: 0.7728 - val_loss: 0.6077 - val_accuracy: 0.7143\n",
            "Epoch 180/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4874 - accuracy: 0.7699 - val_loss: 0.6104 - val_accuracy: 0.7273\n",
            "Epoch 181/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5033 - accuracy: 0.7496 - val_loss: 0.5453 - val_accuracy: 0.7662\n",
            "Epoch 182/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.7656 - val_loss: 0.5572 - val_accuracy: 0.7273\n",
            "Epoch 183/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4864 - accuracy: 0.7583 - val_loss: 0.5611 - val_accuracy: 0.7532\n",
            "Epoch 184/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4870 - accuracy: 0.7554 - val_loss: 0.5462 - val_accuracy: 0.7532\n",
            "Epoch 185/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4901 - accuracy: 0.7656 - val_loss: 0.5534 - val_accuracy: 0.7403\n",
            "Epoch 186/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.7525 - val_loss: 0.5754 - val_accuracy: 0.7143\n",
            "Epoch 187/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.7511 - val_loss: 0.5430 - val_accuracy: 0.7662\n",
            "Epoch 188/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4916 - accuracy: 0.7598 - val_loss: 0.5580 - val_accuracy: 0.7532\n",
            "Epoch 189/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.7540 - val_loss: 0.5556 - val_accuracy: 0.7662\n",
            "Epoch 190/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4813 - accuracy: 0.7699 - val_loss: 0.5618 - val_accuracy: 0.7532\n",
            "Epoch 191/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4882 - accuracy: 0.7612 - val_loss: 0.5553 - val_accuracy: 0.7792\n",
            "Epoch 192/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.7713 - val_loss: 0.5499 - val_accuracy: 0.7532\n",
            "Epoch 193/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.7627 - val_loss: 0.5727 - val_accuracy: 0.7403\n",
            "Epoch 194/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.7627 - val_loss: 0.5809 - val_accuracy: 0.7013\n",
            "Epoch 195/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4949 - accuracy: 0.7496 - val_loss: 0.5675 - val_accuracy: 0.7403\n",
            "Epoch 196/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4938 - accuracy: 0.7410 - val_loss: 0.5706 - val_accuracy: 0.7273\n",
            "Epoch 197/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.7685 - val_loss: 0.5666 - val_accuracy: 0.7143\n",
            "Epoch 198/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.7742 - val_loss: 0.5613 - val_accuracy: 0.7273\n",
            "Epoch 199/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4830 - accuracy: 0.7598 - val_loss: 0.5423 - val_accuracy: 0.7532\n",
            "Epoch 200/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4919 - accuracy: 0.7511 - val_loss: 0.5474 - val_accuracy: 0.7273\n",
            "Epoch 201/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4953 - accuracy: 0.7569 - val_loss: 0.6186 - val_accuracy: 0.7273\n",
            "Epoch 202/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4778 - accuracy: 0.7713 - val_loss: 0.5585 - val_accuracy: 0.7403\n",
            "Epoch 203/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4761 - accuracy: 0.7670 - val_loss: 0.5899 - val_accuracy: 0.7403\n",
            "Epoch 204/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4774 - accuracy: 0.7612 - val_loss: 0.5826 - val_accuracy: 0.7403\n",
            "Epoch 205/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4862 - accuracy: 0.7569 - val_loss: 0.5445 - val_accuracy: 0.7532\n",
            "Epoch 206/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4808 - accuracy: 0.7540 - val_loss: 0.5475 - val_accuracy: 0.7532\n",
            "Epoch 207/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4831 - accuracy: 0.7641 - val_loss: 0.5476 - val_accuracy: 0.7532\n",
            "Epoch 208/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.7699 - val_loss: 0.5535 - val_accuracy: 0.7532\n",
            "Epoch 209/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.7554 - val_loss: 0.5706 - val_accuracy: 0.7403\n",
            "Epoch 210/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4950 - accuracy: 0.7656 - val_loss: 0.5656 - val_accuracy: 0.7143\n",
            "Epoch 211/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4747 - accuracy: 0.7598 - val_loss: 0.5457 - val_accuracy: 0.7403\n",
            "Epoch 212/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.7641 - val_loss: 0.5674 - val_accuracy: 0.7273\n",
            "Epoch 213/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.7627 - val_loss: 0.5568 - val_accuracy: 0.7273\n",
            "Epoch 214/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4762 - accuracy: 0.7713 - val_loss: 0.5678 - val_accuracy: 0.7273\n",
            "Epoch 215/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4815 - accuracy: 0.7670 - val_loss: 0.6058 - val_accuracy: 0.7273\n",
            "Epoch 216/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4894 - accuracy: 0.7554 - val_loss: 0.5392 - val_accuracy: 0.7662\n",
            "Epoch 217/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.7858 - val_loss: 0.5571 - val_accuracy: 0.7532\n",
            "Epoch 218/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.7685 - val_loss: 0.5472 - val_accuracy: 0.7662\n",
            "Epoch 219/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4792 - accuracy: 0.7540 - val_loss: 0.5387 - val_accuracy: 0.7662\n",
            "Epoch 220/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4799 - accuracy: 0.7656 - val_loss: 0.5412 - val_accuracy: 0.7403\n",
            "Epoch 221/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.7612 - val_loss: 0.5904 - val_accuracy: 0.7532\n",
            "Epoch 222/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4781 - accuracy: 0.7583 - val_loss: 0.5581 - val_accuracy: 0.7403\n",
            "Epoch 223/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.7713 - val_loss: 0.5424 - val_accuracy: 0.7662\n",
            "Epoch 224/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7685 - val_loss: 0.5399 - val_accuracy: 0.7662\n",
            "Epoch 225/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4678 - accuracy: 0.7670 - val_loss: 0.5870 - val_accuracy: 0.7403\n",
            "Epoch 226/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4748 - accuracy: 0.7540 - val_loss: 0.5394 - val_accuracy: 0.7662\n",
            "Epoch 227/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7540 - val_loss: 0.5590 - val_accuracy: 0.7143\n",
            "Epoch 228/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4760 - accuracy: 0.7525 - val_loss: 0.5530 - val_accuracy: 0.7143\n",
            "Epoch 229/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4864 - accuracy: 0.7467 - val_loss: 0.5544 - val_accuracy: 0.7273\n",
            "Epoch 230/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.7612 - val_loss: 0.5373 - val_accuracy: 0.7792\n",
            "Epoch 231/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7713 - val_loss: 0.5890 - val_accuracy: 0.6753\n",
            "Epoch 232/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.7554 - val_loss: 0.5757 - val_accuracy: 0.7273\n",
            "Epoch 233/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.7728 - val_loss: 0.5356 - val_accuracy: 0.7792\n",
            "Epoch 234/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4925 - accuracy: 0.7410 - val_loss: 0.5425 - val_accuracy: 0.7662\n",
            "Epoch 235/1000\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7728 - val_loss: 0.5789 - val_accuracy: 0.7403\n",
            "Epoch 236/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.7771 - val_loss: 0.5976 - val_accuracy: 0.7273\n",
            "Epoch 237/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.7540 - val_loss: 0.5514 - val_accuracy: 0.7532\n",
            "Epoch 238/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.7641 - val_loss: 0.6257 - val_accuracy: 0.7013\n",
            "Epoch 239/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4845 - accuracy: 0.7713 - val_loss: 0.5857 - val_accuracy: 0.7532\n",
            "Epoch 240/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.7569 - val_loss: 0.5850 - val_accuracy: 0.7532\n",
            "Epoch 241/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.7728 - val_loss: 0.5455 - val_accuracy: 0.7532\n",
            "Epoch 242/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4845 - accuracy: 0.7511 - val_loss: 0.5390 - val_accuracy: 0.7532\n",
            "Epoch 243/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4672 - accuracy: 0.7757 - val_loss: 0.5367 - val_accuracy: 0.7662\n",
            "Epoch 244/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.7757 - val_loss: 0.5388 - val_accuracy: 0.7403\n",
            "Epoch 245/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7699 - val_loss: 0.5515 - val_accuracy: 0.7532\n",
            "Epoch 246/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7757 - val_loss: 0.5469 - val_accuracy: 0.7403\n",
            "Epoch 247/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7699 - val_loss: 0.5366 - val_accuracy: 0.7662\n",
            "Epoch 248/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.7569 - val_loss: 0.5502 - val_accuracy: 0.7532\n",
            "Epoch 249/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.7713 - val_loss: 0.5458 - val_accuracy: 0.7662\n",
            "Epoch 250/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.7713 - val_loss: 0.5311 - val_accuracy: 0.7792\n",
            "Epoch 251/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7656 - val_loss: 0.5626 - val_accuracy: 0.7143\n",
            "Epoch 252/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.7844 - val_loss: 0.5422 - val_accuracy: 0.7662\n",
            "Epoch 253/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7525 - val_loss: 0.5404 - val_accuracy: 0.7662\n",
            "Epoch 254/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7771 - val_loss: 0.5525 - val_accuracy: 0.7143\n",
            "Epoch 255/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7786 - val_loss: 0.5614 - val_accuracy: 0.7532\n",
            "Epoch 256/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4770 - accuracy: 0.7438 - val_loss: 0.5591 - val_accuracy: 0.7403\n",
            "Epoch 257/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.7771 - val_loss: 0.5421 - val_accuracy: 0.7792\n",
            "Epoch 258/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7728 - val_loss: 0.5598 - val_accuracy: 0.7532\n",
            "Epoch 259/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.7699 - val_loss: 0.5356 - val_accuracy: 0.7662\n",
            "Epoch 260/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4731 - accuracy: 0.7786 - val_loss: 0.5924 - val_accuracy: 0.7143\n",
            "Epoch 261/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.7771 - val_loss: 0.5515 - val_accuracy: 0.7403\n",
            "Epoch 262/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7598 - val_loss: 0.5353 - val_accuracy: 0.7792\n",
            "Epoch 263/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.7728 - val_loss: 0.5981 - val_accuracy: 0.7143\n",
            "Epoch 264/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.7612 - val_loss: 0.5524 - val_accuracy: 0.7403\n",
            "Epoch 265/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4765 - accuracy: 0.7554 - val_loss: 0.5866 - val_accuracy: 0.7532\n",
            "Epoch 266/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.7685 - val_loss: 0.5424 - val_accuracy: 0.7792\n",
            "Epoch 267/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4865 - accuracy: 0.7511 - val_loss: 0.5559 - val_accuracy: 0.7532\n",
            "Epoch 268/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4740 - accuracy: 0.7685 - val_loss: 0.5993 - val_accuracy: 0.7792\n",
            "Epoch 269/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.7685 - val_loss: 0.5430 - val_accuracy: 0.7792\n",
            "Epoch 270/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7786 - val_loss: 0.5634 - val_accuracy: 0.7403\n",
            "Epoch 271/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.7641 - val_loss: 0.5308 - val_accuracy: 0.7922\n",
            "Epoch 272/1000\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7554 - val_loss: 0.5492 - val_accuracy: 0.7532\n",
            "Epoch 273/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5019 - accuracy: 0.7410 - val_loss: 0.5418 - val_accuracy: 0.7662\n",
            "Epoch 274/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.7742 - val_loss: 0.5504 - val_accuracy: 0.7662\n",
            "Epoch 275/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7713 - val_loss: 0.5354 - val_accuracy: 0.7922\n",
            "Epoch 276/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7757 - val_loss: 0.5319 - val_accuracy: 0.7922\n",
            "Epoch 277/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.7815 - val_loss: 0.5487 - val_accuracy: 0.7532\n",
            "Epoch 278/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7598 - val_loss: 0.5730 - val_accuracy: 0.7273\n",
            "Epoch 279/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7641 - val_loss: 0.5601 - val_accuracy: 0.7403\n",
            "Epoch 280/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7713 - val_loss: 0.5297 - val_accuracy: 0.7792\n",
            "Epoch 281/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7670 - val_loss: 0.5620 - val_accuracy: 0.7792\n",
            "Epoch 282/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.7583 - val_loss: 0.5281 - val_accuracy: 0.7792\n",
            "Epoch 283/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7685 - val_loss: 0.5429 - val_accuracy: 0.7662\n",
            "Epoch 284/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.7771 - val_loss: 0.5345 - val_accuracy: 0.8052\n",
            "Epoch 285/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.7858 - val_loss: 0.5879 - val_accuracy: 0.7143\n",
            "Epoch 286/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7598 - val_loss: 0.5607 - val_accuracy: 0.7013\n",
            "Epoch 287/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.7728 - val_loss: 0.5431 - val_accuracy: 0.7662\n",
            "Epoch 288/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4521 - accuracy: 0.7713 - val_loss: 0.5438 - val_accuracy: 0.7792\n",
            "Epoch 289/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7598 - val_loss: 0.5441 - val_accuracy: 0.7532\n",
            "Epoch 290/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7815 - val_loss: 0.5317 - val_accuracy: 0.7792\n",
            "Epoch 291/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7728 - val_loss: 0.5338 - val_accuracy: 0.7792\n",
            "Epoch 292/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.7685 - val_loss: 0.5375 - val_accuracy: 0.8182\n",
            "Epoch 293/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7844 - val_loss: 0.5320 - val_accuracy: 0.7922\n",
            "Epoch 294/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7844 - val_loss: 0.5373 - val_accuracy: 0.7792\n",
            "Epoch 295/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.7699 - val_loss: 0.5440 - val_accuracy: 0.7662\n",
            "Epoch 296/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.7728 - val_loss: 0.5368 - val_accuracy: 0.7662\n",
            "Epoch 297/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4773 - accuracy: 0.7742 - val_loss: 0.5482 - val_accuracy: 0.7532\n",
            "Epoch 298/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.7757 - val_loss: 0.5478 - val_accuracy: 0.7532\n",
            "Epoch 299/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7742 - val_loss: 0.5326 - val_accuracy: 0.7792\n",
            "Epoch 300/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7771 - val_loss: 0.5411 - val_accuracy: 0.7403\n",
            "Epoch 301/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.7800 - val_loss: 0.5208 - val_accuracy: 0.7922\n",
            "Epoch 302/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.7800 - val_loss: 0.5283 - val_accuracy: 0.7922\n",
            "Epoch 303/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.7887 - val_loss: 0.5293 - val_accuracy: 0.8052\n",
            "Epoch 304/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7815 - val_loss: 0.5749 - val_accuracy: 0.7273\n",
            "Epoch 305/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7757 - val_loss: 0.5441 - val_accuracy: 0.7403\n",
            "Epoch 306/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7713 - val_loss: 0.5405 - val_accuracy: 0.7532\n",
            "Epoch 307/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.7757 - val_loss: 0.5955 - val_accuracy: 0.7013\n",
            "Epoch 308/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4916 - accuracy: 0.7612 - val_loss: 0.5836 - val_accuracy: 0.7143\n",
            "Epoch 309/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7656 - val_loss: 0.5302 - val_accuracy: 0.7662\n",
            "Epoch 310/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.7540 - val_loss: 0.5573 - val_accuracy: 0.7532\n",
            "Epoch 311/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7728 - val_loss: 0.5555 - val_accuracy: 0.7922\n",
            "Epoch 312/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4914 - accuracy: 0.7366 - val_loss: 0.5423 - val_accuracy: 0.7662\n",
            "Epoch 313/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.7800 - val_loss: 0.5267 - val_accuracy: 0.7792\n",
            "Epoch 314/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.7771 - val_loss: 0.5243 - val_accuracy: 0.7922\n",
            "Epoch 315/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.7771 - val_loss: 0.5302 - val_accuracy: 0.7792\n",
            "Epoch 316/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.7829 - val_loss: 0.5360 - val_accuracy: 0.7792\n",
            "Epoch 317/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.7844 - val_loss: 0.5222 - val_accuracy: 0.7922\n",
            "Epoch 318/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.7685 - val_loss: 0.5371 - val_accuracy: 0.7532\n",
            "Epoch 319/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.7699 - val_loss: 0.5336 - val_accuracy: 0.7662\n",
            "Epoch 320/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.7858 - val_loss: 0.5221 - val_accuracy: 0.7922\n",
            "Epoch 321/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.7959 - val_loss: 0.5254 - val_accuracy: 0.8182\n",
            "Epoch 322/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.7887 - val_loss: 0.5284 - val_accuracy: 0.7922\n",
            "Epoch 323/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7858 - val_loss: 0.5574 - val_accuracy: 0.7662\n",
            "Epoch 324/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.7858 - val_loss: 0.5449 - val_accuracy: 0.7662\n",
            "Epoch 325/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.7786 - val_loss: 0.5192 - val_accuracy: 0.7922\n",
            "Epoch 326/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.7800 - val_loss: 0.5303 - val_accuracy: 0.7922\n",
            "Epoch 327/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7757 - val_loss: 0.5268 - val_accuracy: 0.7922\n",
            "Epoch 328/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7858 - val_loss: 0.5424 - val_accuracy: 0.7662\n",
            "Epoch 329/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.7656 - val_loss: 0.5549 - val_accuracy: 0.7532\n",
            "Epoch 330/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.7902 - val_loss: 0.5475 - val_accuracy: 0.7403\n",
            "Epoch 331/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7742 - val_loss: 0.5735 - val_accuracy: 0.7273\n",
            "Epoch 332/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.7627 - val_loss: 0.5402 - val_accuracy: 0.7922\n",
            "Epoch 333/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4540 - accuracy: 0.7771 - val_loss: 0.5703 - val_accuracy: 0.7273\n",
            "Epoch 334/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7713 - val_loss: 0.5469 - val_accuracy: 0.7792\n",
            "Epoch 335/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.7974 - val_loss: 0.5226 - val_accuracy: 0.7792\n",
            "Epoch 336/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.7887 - val_loss: 0.5344 - val_accuracy: 0.7922\n",
            "Epoch 337/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.7656 - val_loss: 0.5358 - val_accuracy: 0.8052\n",
            "Epoch 338/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.7786 - val_loss: 0.5302 - val_accuracy: 0.7792\n",
            "Epoch 339/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.7713 - val_loss: 0.5416 - val_accuracy: 0.7532\n",
            "Epoch 340/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4522 - accuracy: 0.7670 - val_loss: 0.5328 - val_accuracy: 0.7662\n",
            "Epoch 341/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7873 - val_loss: 0.5331 - val_accuracy: 0.7792\n",
            "Epoch 342/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.7742 - val_loss: 0.5221 - val_accuracy: 0.7922\n",
            "Epoch 343/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7858 - val_loss: 0.5327 - val_accuracy: 0.7532\n",
            "Epoch 344/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.7786 - val_loss: 0.5417 - val_accuracy: 0.7792\n",
            "Epoch 345/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.7742 - val_loss: 0.5594 - val_accuracy: 0.7273\n",
            "Epoch 346/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7641 - val_loss: 0.5253 - val_accuracy: 0.7532\n",
            "Epoch 347/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7641 - val_loss: 0.5503 - val_accuracy: 0.7662\n",
            "Epoch 348/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.7612 - val_loss: 0.5184 - val_accuracy: 0.8052\n",
            "Epoch 349/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7742 - val_loss: 0.5301 - val_accuracy: 0.7662\n",
            "Epoch 350/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.7800 - val_loss: 0.5287 - val_accuracy: 0.7792\n",
            "Epoch 351/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7742 - val_loss: 0.5478 - val_accuracy: 0.7532\n",
            "Epoch 352/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7829 - val_loss: 0.5132 - val_accuracy: 0.7922\n",
            "Epoch 353/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7713 - val_loss: 0.5615 - val_accuracy: 0.7532\n",
            "Epoch 354/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4546 - accuracy: 0.7685 - val_loss: 0.5261 - val_accuracy: 0.7792\n",
            "Epoch 355/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.7627 - val_loss: 0.5337 - val_accuracy: 0.7922\n",
            "Epoch 356/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7786 - val_loss: 0.5292 - val_accuracy: 0.7532\n",
            "Epoch 357/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.7786 - val_loss: 0.5447 - val_accuracy: 0.7532\n",
            "Epoch 358/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7771 - val_loss: 0.5352 - val_accuracy: 0.7532\n",
            "Epoch 359/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7829 - val_loss: 0.5437 - val_accuracy: 0.7403\n",
            "Epoch 360/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.7815 - val_loss: 0.5251 - val_accuracy: 0.7922\n",
            "Epoch 361/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7771 - val_loss: 0.5208 - val_accuracy: 0.8182\n",
            "Epoch 362/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7815 - val_loss: 0.5474 - val_accuracy: 0.7273\n",
            "Epoch 363/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.7641 - val_loss: 0.5134 - val_accuracy: 0.7792\n",
            "Epoch 364/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.8017 - val_loss: 0.5477 - val_accuracy: 0.7403\n",
            "Epoch 365/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7699 - val_loss: 0.5175 - val_accuracy: 0.8052\n",
            "Epoch 366/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7815 - val_loss: 0.5481 - val_accuracy: 0.7403\n",
            "Epoch 367/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7844 - val_loss: 0.5345 - val_accuracy: 0.7792\n",
            "Epoch 368/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7844 - val_loss: 0.5607 - val_accuracy: 0.7662\n",
            "Epoch 369/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7728 - val_loss: 0.5864 - val_accuracy: 0.7273\n",
            "Epoch 370/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.7931 - val_loss: 0.5194 - val_accuracy: 0.7792\n",
            "Epoch 371/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7815 - val_loss: 0.5175 - val_accuracy: 0.7922\n",
            "Epoch 372/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7902 - val_loss: 0.5365 - val_accuracy: 0.7273\n",
            "Epoch 373/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.7800 - val_loss: 0.5481 - val_accuracy: 0.7532\n",
            "Epoch 374/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7873 - val_loss: 0.5327 - val_accuracy: 0.7922\n",
            "Epoch 375/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.7656 - val_loss: 0.5199 - val_accuracy: 0.7792\n",
            "Epoch 376/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7757 - val_loss: 0.5186 - val_accuracy: 0.8052\n",
            "Epoch 377/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.7656 - val_loss: 0.5181 - val_accuracy: 0.7922\n",
            "Epoch 378/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.7916 - val_loss: 0.5118 - val_accuracy: 0.7922\n",
            "Epoch 379/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.7858 - val_loss: 0.5131 - val_accuracy: 0.7922\n",
            "Epoch 380/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.7771 - val_loss: 0.5711 - val_accuracy: 0.7532\n",
            "Epoch 381/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.7713 - val_loss: 0.5222 - val_accuracy: 0.7532\n",
            "Epoch 382/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.7757 - val_loss: 0.5430 - val_accuracy: 0.7532\n",
            "Epoch 383/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.7771 - val_loss: 0.5337 - val_accuracy: 0.7792\n",
            "Epoch 384/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.8003 - val_loss: 0.5202 - val_accuracy: 0.7922\n",
            "Epoch 385/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7569 - val_loss: 0.5290 - val_accuracy: 0.7792\n",
            "Epoch 386/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.7786 - val_loss: 0.5225 - val_accuracy: 0.7662\n",
            "Epoch 387/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.7815 - val_loss: 0.5305 - val_accuracy: 0.7662\n",
            "Epoch 388/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.7713 - val_loss: 0.5458 - val_accuracy: 0.7532\n",
            "Epoch 389/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7742 - val_loss: 0.5294 - val_accuracy: 0.7792\n",
            "Epoch 390/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4548 - accuracy: 0.7815 - val_loss: 0.5438 - val_accuracy: 0.7532\n",
            "Epoch 391/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7771 - val_loss: 0.5307 - val_accuracy: 0.7532\n",
            "Epoch 392/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7786 - val_loss: 0.5170 - val_accuracy: 0.7922\n",
            "Epoch 393/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7757 - val_loss: 0.5266 - val_accuracy: 0.7662\n",
            "Epoch 394/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7873 - val_loss: 0.5229 - val_accuracy: 0.7662\n",
            "Epoch 395/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.7713 - val_loss: 0.5416 - val_accuracy: 0.7403\n",
            "Epoch 396/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7713 - val_loss: 0.5376 - val_accuracy: 0.7403\n",
            "Epoch 397/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.7685 - val_loss: 0.5371 - val_accuracy: 0.7403\n",
            "Epoch 398/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.8003 - val_loss: 0.5199 - val_accuracy: 0.7792\n",
            "Epoch 399/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.7699 - val_loss: 0.5228 - val_accuracy: 0.7662\n",
            "Epoch 400/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.7858 - val_loss: 0.5169 - val_accuracy: 0.7922\n",
            "Epoch 401/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.7931 - val_loss: 0.5335 - val_accuracy: 0.7273\n",
            "Epoch 402/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.7873 - val_loss: 0.5427 - val_accuracy: 0.7403\n",
            "Epoch 403/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7685 - val_loss: 0.5157 - val_accuracy: 0.8052\n",
            "Epoch 404/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4572 - accuracy: 0.7829 - val_loss: 0.5401 - val_accuracy: 0.7532\n",
            "Epoch 405/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.7786 - val_loss: 0.5412 - val_accuracy: 0.7403\n",
            "Epoch 406/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.7873 - val_loss: 0.5012 - val_accuracy: 0.7922\n",
            "Epoch 407/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7844 - val_loss: 0.5152 - val_accuracy: 0.8052\n",
            "Epoch 408/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.7742 - val_loss: 0.5332 - val_accuracy: 0.7792\n",
            "Epoch 409/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.7713 - val_loss: 0.5356 - val_accuracy: 0.7532\n",
            "Epoch 410/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7902 - val_loss: 0.5410 - val_accuracy: 0.7532\n",
            "Epoch 411/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7931 - val_loss: 0.5211 - val_accuracy: 0.7662\n",
            "Epoch 412/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7844 - val_loss: 0.5169 - val_accuracy: 0.7922\n",
            "Epoch 413/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.7829 - val_loss: 0.5213 - val_accuracy: 0.8052\n",
            "Epoch 414/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.7786 - val_loss: 0.5232 - val_accuracy: 0.7792\n",
            "Epoch 415/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.8061 - val_loss: 0.5482 - val_accuracy: 0.7532\n",
            "Epoch 416/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.7699 - val_loss: 0.5640 - val_accuracy: 0.7403\n",
            "Epoch 417/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.7670 - val_loss: 0.5151 - val_accuracy: 0.7922\n",
            "Epoch 418/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.7554 - val_loss: 0.5258 - val_accuracy: 0.7403\n",
            "Epoch 419/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7858 - val_loss: 0.5020 - val_accuracy: 0.7922\n",
            "Epoch 420/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7771 - val_loss: 0.5348 - val_accuracy: 0.7403\n",
            "Epoch 421/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.7959 - val_loss: 0.5120 - val_accuracy: 0.7922\n",
            "Epoch 422/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7858 - val_loss: 0.5083 - val_accuracy: 0.7922\n",
            "Epoch 423/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.7786 - val_loss: 0.5138 - val_accuracy: 0.7662\n",
            "Epoch 424/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7931 - val_loss: 0.5123 - val_accuracy: 0.7922\n",
            "Epoch 425/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7988 - val_loss: 0.5288 - val_accuracy: 0.7403\n",
            "Epoch 426/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7786 - val_loss: 0.5456 - val_accuracy: 0.7273\n",
            "Epoch 427/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.7916 - val_loss: 0.5191 - val_accuracy: 0.7792\n",
            "Epoch 428/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7844 - val_loss: 0.5253 - val_accuracy: 0.7662\n",
            "Epoch 429/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7858 - val_loss: 0.5179 - val_accuracy: 0.7922\n",
            "Epoch 430/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7728 - val_loss: 0.5893 - val_accuracy: 0.7273\n",
            "Epoch 431/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.8133 - val_loss: 0.5791 - val_accuracy: 0.7273\n",
            "Epoch 432/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.7844 - val_loss: 0.5137 - val_accuracy: 0.7922\n",
            "Epoch 433/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.7742 - val_loss: 0.5249 - val_accuracy: 0.7403\n",
            "Epoch 434/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.7844 - val_loss: 0.5158 - val_accuracy: 0.8052\n",
            "Epoch 435/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7873 - val_loss: 0.5555 - val_accuracy: 0.7403\n",
            "Epoch 436/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7887 - val_loss: 0.5356 - val_accuracy: 0.7662\n",
            "Epoch 437/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7887 - val_loss: 0.5053 - val_accuracy: 0.7662\n",
            "Epoch 438/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7887 - val_loss: 0.5038 - val_accuracy: 0.8052\n",
            "Epoch 439/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.7713 - val_loss: 0.5356 - val_accuracy: 0.7273\n",
            "Epoch 440/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7786 - val_loss: 0.5335 - val_accuracy: 0.7662\n",
            "Epoch 441/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7829 - val_loss: 0.5233 - val_accuracy: 0.7922\n",
            "Epoch 442/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.7959 - val_loss: 0.4975 - val_accuracy: 0.7792\n",
            "Epoch 443/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7873 - val_loss: 0.5241 - val_accuracy: 0.7662\n",
            "Epoch 444/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7945 - val_loss: 0.5135 - val_accuracy: 0.7922\n",
            "Epoch 445/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.7771 - val_loss: 0.5470 - val_accuracy: 0.7403\n",
            "Epoch 446/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7728 - val_loss: 0.5284 - val_accuracy: 0.7532\n",
            "Epoch 447/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.7873 - val_loss: 0.5175 - val_accuracy: 0.7922\n",
            "Epoch 448/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7902 - val_loss: 0.5101 - val_accuracy: 0.7922\n",
            "Epoch 449/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.8061 - val_loss: 0.5168 - val_accuracy: 0.7792\n",
            "Epoch 450/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7858 - val_loss: 0.5151 - val_accuracy: 0.7922\n",
            "Epoch 451/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.7858 - val_loss: 0.5458 - val_accuracy: 0.7403\n",
            "Epoch 452/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.7945 - val_loss: 0.5205 - val_accuracy: 0.7792\n",
            "Epoch 453/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7974 - val_loss: 0.5101 - val_accuracy: 0.7922\n",
            "Epoch 454/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7742 - val_loss: 0.5258 - val_accuracy: 0.7273\n",
            "Epoch 455/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.7959 - val_loss: 0.5451 - val_accuracy: 0.7532\n",
            "Epoch 456/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.7829 - val_loss: 0.5245 - val_accuracy: 0.7403\n",
            "Epoch 457/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7829 - val_loss: 0.5130 - val_accuracy: 0.7662\n",
            "Epoch 458/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7858 - val_loss: 0.5239 - val_accuracy: 0.7532\n",
            "Epoch 459/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7858 - val_loss: 0.5175 - val_accuracy: 0.7792\n",
            "Epoch 460/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7858 - val_loss: 0.5089 - val_accuracy: 0.7792\n",
            "Epoch 461/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.7873 - val_loss: 0.5193 - val_accuracy: 0.7792\n",
            "Epoch 462/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7829 - val_loss: 0.5045 - val_accuracy: 0.7922\n",
            "Epoch 463/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.7916 - val_loss: 0.5205 - val_accuracy: 0.7792\n",
            "Epoch 464/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.7873 - val_loss: 0.5142 - val_accuracy: 0.7532\n",
            "Epoch 465/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7959 - val_loss: 0.5238 - val_accuracy: 0.7922\n",
            "Epoch 466/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7829 - val_loss: 0.5654 - val_accuracy: 0.7403\n",
            "Epoch 467/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.7844 - val_loss: 0.5214 - val_accuracy: 0.7922\n",
            "Epoch 468/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.8003 - val_loss: 0.5118 - val_accuracy: 0.7532\n",
            "Epoch 469/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7959 - val_loss: 0.5703 - val_accuracy: 0.7403\n",
            "Epoch 470/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.7858 - val_loss: 0.5188 - val_accuracy: 0.7662\n",
            "Epoch 471/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.7844 - val_loss: 0.5314 - val_accuracy: 0.7403\n",
            "Epoch 472/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7728 - val_loss: 0.5686 - val_accuracy: 0.7273\n",
            "Epoch 473/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.7786 - val_loss: 0.5199 - val_accuracy: 0.7532\n",
            "Epoch 474/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.7858 - val_loss: 0.5219 - val_accuracy: 0.7792\n",
            "Epoch 475/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.7685 - val_loss: 0.5084 - val_accuracy: 0.7532\n",
            "Epoch 476/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.7916 - val_loss: 0.5057 - val_accuracy: 0.7792\n",
            "Epoch 477/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7887 - val_loss: 0.5037 - val_accuracy: 0.7922\n",
            "Epoch 478/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7858 - val_loss: 0.5318 - val_accuracy: 0.7532\n",
            "Epoch 479/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.7757 - val_loss: 0.5671 - val_accuracy: 0.7403\n",
            "Epoch 480/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7887 - val_loss: 0.5196 - val_accuracy: 0.7792\n",
            "Epoch 481/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7887 - val_loss: 0.5114 - val_accuracy: 0.7792\n",
            "Epoch 482/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4216 - accuracy: 0.7873 - val_loss: 0.5276 - val_accuracy: 0.7532\n",
            "Epoch 483/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7829 - val_loss: 0.5517 - val_accuracy: 0.7403\n",
            "Epoch 484/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7858 - val_loss: 0.5149 - val_accuracy: 0.7273\n",
            "Epoch 485/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.7844 - val_loss: 0.5208 - val_accuracy: 0.7792\n",
            "Epoch 486/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.7931 - val_loss: 0.5211 - val_accuracy: 0.7532\n",
            "Epoch 487/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7858 - val_loss: 0.6168 - val_accuracy: 0.7143\n",
            "Epoch 488/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.7742 - val_loss: 0.5055 - val_accuracy: 0.7792\n",
            "Epoch 489/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4152 - accuracy: 0.8032 - val_loss: 0.5540 - val_accuracy: 0.7403\n",
            "Epoch 490/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7931 - val_loss: 0.5077 - val_accuracy: 0.7532\n",
            "Epoch 491/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.7916 - val_loss: 0.5116 - val_accuracy: 0.7662\n",
            "Epoch 492/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.7959 - val_loss: 0.4968 - val_accuracy: 0.7922\n",
            "Epoch 493/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.7974 - val_loss: 0.5060 - val_accuracy: 0.8052\n",
            "Epoch 494/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7902 - val_loss: 0.5082 - val_accuracy: 0.7922\n",
            "Epoch 495/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7873 - val_loss: 0.5035 - val_accuracy: 0.7922\n",
            "Epoch 496/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.7887 - val_loss: 0.5045 - val_accuracy: 0.7792\n",
            "Epoch 497/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.8032 - val_loss: 0.5042 - val_accuracy: 0.7792\n",
            "Epoch 498/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.7873 - val_loss: 0.5002 - val_accuracy: 0.7922\n",
            "Epoch 499/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.8003 - val_loss: 0.4995 - val_accuracy: 0.7922\n",
            "Epoch 500/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.8017 - val_loss: 0.5669 - val_accuracy: 0.7403\n",
            "Epoch 501/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7902 - val_loss: 0.5126 - val_accuracy: 0.7792\n",
            "Epoch 502/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7974 - val_loss: 0.5011 - val_accuracy: 0.7792\n",
            "Epoch 503/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.7873 - val_loss: 0.5388 - val_accuracy: 0.7532\n",
            "Epoch 504/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.7887 - val_loss: 0.5101 - val_accuracy: 0.7792\n",
            "Epoch 505/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.7873 - val_loss: 0.5032 - val_accuracy: 0.7532\n",
            "Epoch 506/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.7713 - val_loss: 0.5003 - val_accuracy: 0.7792\n",
            "Epoch 507/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.7988 - val_loss: 0.5142 - val_accuracy: 0.7662\n",
            "Epoch 508/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.7916 - val_loss: 0.5057 - val_accuracy: 0.7792\n",
            "Epoch 509/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.7858 - val_loss: 0.5079 - val_accuracy: 0.7922\n",
            "Epoch 510/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7844 - val_loss: 0.5344 - val_accuracy: 0.7532\n",
            "Epoch 511/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.7945 - val_loss: 0.4972 - val_accuracy: 0.7922\n",
            "Epoch 512/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.7815 - val_loss: 0.5080 - val_accuracy: 0.7662\n",
            "Epoch 513/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.7945 - val_loss: 0.4970 - val_accuracy: 0.7662\n",
            "Epoch 514/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.7873 - val_loss: 0.5375 - val_accuracy: 0.7662\n",
            "Epoch 515/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4155 - accuracy: 0.8003 - val_loss: 0.4938 - val_accuracy: 0.7792\n",
            "Epoch 516/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7974 - val_loss: 0.4977 - val_accuracy: 0.7662\n",
            "Epoch 517/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.7916 - val_loss: 0.4898 - val_accuracy: 0.8052\n",
            "Epoch 518/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7902 - val_loss: 0.4988 - val_accuracy: 0.7922\n",
            "Epoch 519/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.7988 - val_loss: 0.4903 - val_accuracy: 0.7792\n",
            "Epoch 520/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.7902 - val_loss: 0.4953 - val_accuracy: 0.7922\n",
            "Epoch 521/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7829 - val_loss: 0.4993 - val_accuracy: 0.7792\n",
            "Epoch 522/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.7974 - val_loss: 0.5175 - val_accuracy: 0.7532\n",
            "Epoch 523/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7887 - val_loss: 0.4966 - val_accuracy: 0.7922\n",
            "Epoch 524/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.7858 - val_loss: 0.5074 - val_accuracy: 0.7792\n",
            "Epoch 525/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7844 - val_loss: 0.4994 - val_accuracy: 0.7922\n",
            "Epoch 526/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.7887 - val_loss: 0.5117 - val_accuracy: 0.7403\n",
            "Epoch 527/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7757 - val_loss: 0.5542 - val_accuracy: 0.7273\n",
            "Epoch 528/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.7873 - val_loss: 0.5626 - val_accuracy: 0.7273\n",
            "Epoch 529/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7916 - val_loss: 0.5101 - val_accuracy: 0.7532\n",
            "Epoch 530/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.8104 - val_loss: 0.4979 - val_accuracy: 0.7792\n",
            "Epoch 531/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.7931 - val_loss: 0.4919 - val_accuracy: 0.7792\n",
            "Epoch 532/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7873 - val_loss: 0.4845 - val_accuracy: 0.7922\n",
            "Epoch 533/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.8046 - val_loss: 0.4983 - val_accuracy: 0.8052\n",
            "Epoch 534/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7873 - val_loss: 0.4800 - val_accuracy: 0.7792\n",
            "Epoch 535/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.7887 - val_loss: 0.5224 - val_accuracy: 0.7532\n",
            "Epoch 536/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.7945 - val_loss: 0.5138 - val_accuracy: 0.7532\n",
            "Epoch 537/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.7873 - val_loss: 0.4964 - val_accuracy: 0.7792\n",
            "Epoch 538/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4113 - accuracy: 0.7887 - val_loss: 0.4876 - val_accuracy: 0.7792\n",
            "Epoch 539/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.7887 - val_loss: 0.4873 - val_accuracy: 0.7922\n",
            "Epoch 540/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.7873 - val_loss: 0.4965 - val_accuracy: 0.7662\n",
            "Epoch 541/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.7988 - val_loss: 0.5350 - val_accuracy: 0.7403\n",
            "Epoch 542/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.7945 - val_loss: 0.5301 - val_accuracy: 0.7532\n",
            "Epoch 543/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.7959 - val_loss: 0.4991 - val_accuracy: 0.7662\n",
            "Epoch 544/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.7945 - val_loss: 0.5046 - val_accuracy: 0.7662\n",
            "Epoch 545/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.7988 - val_loss: 0.4915 - val_accuracy: 0.7922\n",
            "Epoch 546/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.7988 - val_loss: 0.4902 - val_accuracy: 0.7922\n",
            "Epoch 547/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4143 - accuracy: 0.7974 - val_loss: 0.4926 - val_accuracy: 0.7792\n",
            "Epoch 548/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.8003 - val_loss: 0.5219 - val_accuracy: 0.7532\n",
            "Epoch 549/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.7988 - val_loss: 0.5040 - val_accuracy: 0.7662\n",
            "Epoch 550/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.7974 - val_loss: 0.5041 - val_accuracy: 0.7922\n",
            "Epoch 551/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.8003 - val_loss: 0.4916 - val_accuracy: 0.7922\n",
            "Epoch 552/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4144 - accuracy: 0.8017 - val_loss: 0.4969 - val_accuracy: 0.7922\n",
            "Epoch 553/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.7873 - val_loss: 0.4927 - val_accuracy: 0.7792\n",
            "Epoch 554/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.7959 - val_loss: 0.4997 - val_accuracy: 0.7662\n",
            "Epoch 555/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4055 - accuracy: 0.7959 - val_loss: 0.5035 - val_accuracy: 0.7532\n",
            "Epoch 556/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4143 - accuracy: 0.7902 - val_loss: 0.5127 - val_accuracy: 0.7532\n",
            "Epoch 557/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4165 - accuracy: 0.8032 - val_loss: 0.4964 - val_accuracy: 0.7792\n",
            "Epoch 558/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.7815 - val_loss: 0.4994 - val_accuracy: 0.7792\n",
            "Epoch 559/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.7916 - val_loss: 0.4990 - val_accuracy: 0.7273\n",
            "Epoch 560/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.8017 - val_loss: 0.5147 - val_accuracy: 0.7532\n",
            "Epoch 561/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.7902 - val_loss: 0.4954 - val_accuracy: 0.7532\n",
            "Epoch 562/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.7916 - val_loss: 0.5074 - val_accuracy: 0.7662\n",
            "Epoch 563/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.7931 - val_loss: 0.5121 - val_accuracy: 0.7662\n",
            "Epoch 564/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.7974 - val_loss: 0.5023 - val_accuracy: 0.7662\n",
            "Epoch 565/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.8032 - val_loss: 0.4868 - val_accuracy: 0.7792\n",
            "Epoch 566/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.7873 - val_loss: 0.4862 - val_accuracy: 0.7922\n",
            "Epoch 567/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4103 - accuracy: 0.7916 - val_loss: 0.4908 - val_accuracy: 0.7662\n",
            "Epoch 568/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4155 - accuracy: 0.7916 - val_loss: 0.4797 - val_accuracy: 0.7792\n",
            "Epoch 569/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7916 - val_loss: 0.4931 - val_accuracy: 0.7922\n",
            "Epoch 570/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.8003 - val_loss: 0.4877 - val_accuracy: 0.7922\n",
            "Epoch 571/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.7988 - val_loss: 0.4943 - val_accuracy: 0.7922\n",
            "Epoch 572/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4167 - accuracy: 0.8003 - val_loss: 0.5128 - val_accuracy: 0.7532\n",
            "Epoch 573/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4063 - accuracy: 0.7988 - val_loss: 0.4952 - val_accuracy: 0.7922\n",
            "Epoch 574/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.7873 - val_loss: 0.4930 - val_accuracy: 0.7922\n",
            "Epoch 575/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.7931 - val_loss: 0.5064 - val_accuracy: 0.7662\n",
            "Epoch 576/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.7988 - val_loss: 0.4883 - val_accuracy: 0.7922\n",
            "Epoch 577/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.7931 - val_loss: 0.4883 - val_accuracy: 0.7792\n",
            "Epoch 578/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.7902 - val_loss: 0.4885 - val_accuracy: 0.7792\n",
            "Epoch 579/1000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.7902 - val_loss: 0.5233 - val_accuracy: 0.7532\n",
            "Epoch 580/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4181 - accuracy: 0.7916 - val_loss: 0.5086 - val_accuracy: 0.7532\n",
            "Epoch 581/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.8032 - val_loss: 0.4999 - val_accuracy: 0.7662\n",
            "Epoch 582/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.7945 - val_loss: 0.5533 - val_accuracy: 0.7403\n",
            "Epoch 583/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.8003 - val_loss: 0.5012 - val_accuracy: 0.7662\n",
            "Epoch 584/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.7916 - val_loss: 0.4791 - val_accuracy: 0.7922\n",
            "Epoch 585/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.7887 - val_loss: 0.5099 - val_accuracy: 0.7532\n",
            "Epoch 586/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.8003 - val_loss: 0.4920 - val_accuracy: 0.7532\n",
            "Epoch 587/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.7931 - val_loss: 0.5041 - val_accuracy: 0.7792\n",
            "Epoch 588/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4103 - accuracy: 0.7887 - val_loss: 0.5037 - val_accuracy: 0.7532\n",
            "Epoch 589/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.7902 - val_loss: 0.5121 - val_accuracy: 0.7403\n",
            "Epoch 590/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4134 - accuracy: 0.7974 - val_loss: 0.4892 - val_accuracy: 0.7662\n",
            "Epoch 591/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.7974 - val_loss: 0.4913 - val_accuracy: 0.7662\n",
            "Epoch 592/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4146 - accuracy: 0.8003 - val_loss: 0.4779 - val_accuracy: 0.8052\n",
            "Epoch 593/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8003 - val_loss: 0.4829 - val_accuracy: 0.7922\n",
            "Epoch 594/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.7742 - val_loss: 0.5156 - val_accuracy: 0.7532\n",
            "Epoch 595/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.7959 - val_loss: 0.4845 - val_accuracy: 0.8052\n",
            "Epoch 596/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4109 - accuracy: 0.8003 - val_loss: 0.4814 - val_accuracy: 0.7792\n",
            "Epoch 597/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.8003 - val_loss: 0.4840 - val_accuracy: 0.7792\n",
            "Epoch 598/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4099 - accuracy: 0.7974 - val_loss: 0.4973 - val_accuracy: 0.7922\n",
            "Epoch 599/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.7829 - val_loss: 0.4789 - val_accuracy: 0.7792\n",
            "Epoch 600/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.8003 - val_loss: 0.4793 - val_accuracy: 0.8052\n",
            "Epoch 601/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.7974 - val_loss: 0.4883 - val_accuracy: 0.7792\n",
            "Epoch 602/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4133 - accuracy: 0.7988 - val_loss: 0.4801 - val_accuracy: 0.8182\n",
            "Epoch 603/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4106 - accuracy: 0.7916 - val_loss: 0.4940 - val_accuracy: 0.7792\n",
            "Epoch 604/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7858 - val_loss: 0.4789 - val_accuracy: 0.8052\n",
            "Epoch 605/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4135 - accuracy: 0.7959 - val_loss: 0.4916 - val_accuracy: 0.7532\n",
            "Epoch 606/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8046 - val_loss: 0.4774 - val_accuracy: 0.7662\n",
            "Epoch 607/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4085 - accuracy: 0.7959 - val_loss: 0.4873 - val_accuracy: 0.7662\n",
            "Epoch 608/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4024 - accuracy: 0.8119 - val_loss: 0.4924 - val_accuracy: 0.7662\n",
            "Epoch 609/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.7858 - val_loss: 0.4764 - val_accuracy: 0.7922\n",
            "Epoch 610/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4160 - accuracy: 0.8017 - val_loss: 0.5166 - val_accuracy: 0.7532\n",
            "Epoch 611/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7902 - val_loss: 0.4765 - val_accuracy: 0.7532\n",
            "Epoch 612/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.7931 - val_loss: 0.4991 - val_accuracy: 0.7532\n",
            "Epoch 613/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.7931 - val_loss: 0.4767 - val_accuracy: 0.8182\n",
            "Epoch 614/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4052 - accuracy: 0.8003 - val_loss: 0.4875 - val_accuracy: 0.7532\n",
            "Epoch 615/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.7974 - val_loss: 0.4756 - val_accuracy: 0.7922\n",
            "Epoch 616/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7786 - val_loss: 0.4711 - val_accuracy: 0.8052\n",
            "Epoch 617/1000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4151 - accuracy: 0.7873 - val_loss: 0.4795 - val_accuracy: 0.7922\n",
            "Epoch 618/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.7974 - val_loss: 0.4791 - val_accuracy: 0.7792\n",
            "Epoch 619/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.8003 - val_loss: 0.4919 - val_accuracy: 0.8052\n",
            "Epoch 620/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.7829 - val_loss: 0.4812 - val_accuracy: 0.8052\n",
            "Epoch 621/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.7771 - val_loss: 0.4750 - val_accuracy: 0.7792\n",
            "Epoch 622/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.7945 - val_loss: 0.4866 - val_accuracy: 0.7662\n",
            "Epoch 623/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4148 - accuracy: 0.8017 - val_loss: 0.4697 - val_accuracy: 0.7792\n",
            "Epoch 624/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.8032 - val_loss: 0.4957 - val_accuracy: 0.7532\n",
            "Epoch 625/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4102 - accuracy: 0.7974 - val_loss: 0.5015 - val_accuracy: 0.7532\n",
            "Epoch 626/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8133 - val_loss: 0.4732 - val_accuracy: 0.7792\n",
            "Epoch 627/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4110 - accuracy: 0.7902 - val_loss: 0.4699 - val_accuracy: 0.8052\n",
            "Epoch 628/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.7945 - val_loss: 0.4732 - val_accuracy: 0.7792\n",
            "Epoch 629/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4099 - accuracy: 0.7988 - val_loss: 0.4756 - val_accuracy: 0.7662\n",
            "Epoch 630/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.8032 - val_loss: 0.4971 - val_accuracy: 0.7403\n",
            "Epoch 631/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8119 - val_loss: 0.4720 - val_accuracy: 0.7792\n",
            "Epoch 632/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.7959 - val_loss: 0.4836 - val_accuracy: 0.7922\n",
            "Epoch 633/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.7945 - val_loss: 0.4824 - val_accuracy: 0.8052\n",
            "Epoch 634/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4126 - accuracy: 0.7945 - val_loss: 0.4872 - val_accuracy: 0.7532\n",
            "Epoch 635/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8003 - val_loss: 0.4672 - val_accuracy: 0.7922\n",
            "Epoch 636/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.7974 - val_loss: 0.4814 - val_accuracy: 0.7532\n",
            "Epoch 637/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8003 - val_loss: 0.4963 - val_accuracy: 0.7403\n",
            "Epoch 638/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4047 - accuracy: 0.7988 - val_loss: 0.4829 - val_accuracy: 0.7532\n",
            "Epoch 639/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4068 - accuracy: 0.8017 - val_loss: 0.4812 - val_accuracy: 0.7792\n",
            "Epoch 640/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.7959 - val_loss: 0.4730 - val_accuracy: 0.8052\n",
            "Epoch 641/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4127 - accuracy: 0.7959 - val_loss: 0.4868 - val_accuracy: 0.7403\n",
            "Epoch 642/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.8061 - val_loss: 0.4890 - val_accuracy: 0.7662\n",
            "Epoch 643/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4092 - accuracy: 0.8061 - val_loss: 0.4724 - val_accuracy: 0.7922\n",
            "Epoch 644/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.8017 - val_loss: 0.4712 - val_accuracy: 0.8052\n",
            "Epoch 645/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4058 - accuracy: 0.8017 - val_loss: 0.4831 - val_accuracy: 0.7662\n",
            "Epoch 646/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4061 - accuracy: 0.8017 - val_loss: 0.4916 - val_accuracy: 0.7662\n",
            "Epoch 647/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4113 - accuracy: 0.7974 - val_loss: 0.4728 - val_accuracy: 0.7662\n",
            "Epoch 648/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4102 - accuracy: 0.7988 - val_loss: 0.4823 - val_accuracy: 0.7792\n",
            "Epoch 649/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.7974 - val_loss: 0.4815 - val_accuracy: 0.7532\n",
            "Epoch 650/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4024 - accuracy: 0.8003 - val_loss: 0.4728 - val_accuracy: 0.7792\n",
            "Epoch 651/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.8104 - val_loss: 0.4803 - val_accuracy: 0.7403\n",
            "Epoch 652/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.7931 - val_loss: 0.4768 - val_accuracy: 0.8052\n",
            "Epoch 653/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4084 - accuracy: 0.7873 - val_loss: 0.4702 - val_accuracy: 0.7792\n",
            "Epoch 654/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4059 - accuracy: 0.7916 - val_loss: 0.4948 - val_accuracy: 0.7403\n",
            "Epoch 655/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8046 - val_loss: 0.4846 - val_accuracy: 0.7532\n",
            "Epoch 656/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4039 - accuracy: 0.7974 - val_loss: 0.4836 - val_accuracy: 0.7662\n",
            "Epoch 657/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4135 - accuracy: 0.7916 - val_loss: 0.4810 - val_accuracy: 0.7662\n",
            "Epoch 658/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.7988 - val_loss: 0.4770 - val_accuracy: 0.7792\n",
            "Epoch 659/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7786 - val_loss: 0.4699 - val_accuracy: 0.7662\n",
            "Epoch 660/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.8003 - val_loss: 0.4696 - val_accuracy: 0.7792\n",
            "Epoch 661/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.7916 - val_loss: 0.4881 - val_accuracy: 0.7532\n",
            "Epoch 662/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8046 - val_loss: 0.4661 - val_accuracy: 0.7792\n",
            "Epoch 663/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.8032 - val_loss: 0.4834 - val_accuracy: 0.7792\n",
            "Epoch 664/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.8003 - val_loss: 0.4625 - val_accuracy: 0.7922\n",
            "Epoch 665/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4173 - accuracy: 0.7959 - val_loss: 0.4901 - val_accuracy: 0.7532\n",
            "Epoch 666/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8017 - val_loss: 0.4732 - val_accuracy: 0.7792\n",
            "Epoch 667/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4022 - accuracy: 0.7988 - val_loss: 0.5046 - val_accuracy: 0.7532\n",
            "Epoch 668/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.7974 - val_loss: 0.4749 - val_accuracy: 0.8052\n",
            "Epoch 669/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4110 - accuracy: 0.7988 - val_loss: 0.4801 - val_accuracy: 0.7662\n",
            "Epoch 670/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8017 - val_loss: 0.4768 - val_accuracy: 0.7792\n",
            "Epoch 671/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4052 - accuracy: 0.8032 - val_loss: 0.4780 - val_accuracy: 0.7792\n",
            "Epoch 672/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4000 - accuracy: 0.7945 - val_loss: 0.4687 - val_accuracy: 0.7792\n",
            "Epoch 673/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4012 - accuracy: 0.8090 - val_loss: 0.4747 - val_accuracy: 0.7922\n",
            "Epoch 674/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4097 - accuracy: 0.7974 - val_loss: 0.4859 - val_accuracy: 0.7662\n",
            "Epoch 675/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7873 - val_loss: 0.4873 - val_accuracy: 0.7532\n",
            "Epoch 676/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.7887 - val_loss: 0.4867 - val_accuracy: 0.7792\n",
            "Epoch 677/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4045 - accuracy: 0.8017 - val_loss: 0.4696 - val_accuracy: 0.7922\n",
            "Epoch 678/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.7844 - val_loss: 0.4924 - val_accuracy: 0.7532\n",
            "Epoch 679/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.7931 - val_loss: 0.4782 - val_accuracy: 0.7792\n",
            "Epoch 680/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4143 - accuracy: 0.8133 - val_loss: 0.4750 - val_accuracy: 0.7792\n",
            "Epoch 681/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4050 - accuracy: 0.8119 - val_loss: 0.4836 - val_accuracy: 0.7792\n",
            "Epoch 682/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4053 - accuracy: 0.8017 - val_loss: 0.5238 - val_accuracy: 0.7662\n",
            "Epoch 683/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.7742 - val_loss: 0.5089 - val_accuracy: 0.7403\n",
            "Epoch 684/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.7988 - val_loss: 0.4974 - val_accuracy: 0.7792\n",
            "Epoch 685/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8133 - val_loss: 0.4721 - val_accuracy: 0.7532\n",
            "Epoch 686/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.7916 - val_loss: 0.4706 - val_accuracy: 0.8052\n",
            "Epoch 687/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7699 - val_loss: 0.4645 - val_accuracy: 0.8182\n",
            "Epoch 688/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.7988 - val_loss: 0.4755 - val_accuracy: 0.7792\n",
            "Epoch 689/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4018 - accuracy: 0.8003 - val_loss: 0.4669 - val_accuracy: 0.8182\n",
            "Epoch 690/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4053 - accuracy: 0.7887 - val_loss: 0.5109 - val_accuracy: 0.7662\n",
            "Epoch 691/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.7902 - val_loss: 0.5368 - val_accuracy: 0.7532\n",
            "Epoch 692/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7858 - val_loss: 0.5039 - val_accuracy: 0.7403\n",
            "Epoch 693/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4104 - accuracy: 0.7887 - val_loss: 0.4838 - val_accuracy: 0.7532\n",
            "Epoch 694/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3972 - accuracy: 0.8090 - val_loss: 0.4758 - val_accuracy: 0.7922\n",
            "Epoch 695/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4060 - accuracy: 0.7988 - val_loss: 0.4741 - val_accuracy: 0.7792\n",
            "Epoch 696/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.8046 - val_loss: 0.4715 - val_accuracy: 0.8052\n",
            "Epoch 697/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4051 - accuracy: 0.8017 - val_loss: 0.4607 - val_accuracy: 0.8052\n",
            "Epoch 698/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3984 - accuracy: 0.8119 - val_loss: 0.4750 - val_accuracy: 0.7792\n",
            "Epoch 699/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4081 - accuracy: 0.7916 - val_loss: 0.4599 - val_accuracy: 0.7792\n",
            "Epoch 700/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.7988 - val_loss: 0.4819 - val_accuracy: 0.7662\n",
            "Epoch 701/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4014 - accuracy: 0.8061 - val_loss: 0.5005 - val_accuracy: 0.7532\n",
            "Epoch 702/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4023 - accuracy: 0.8003 - val_loss: 0.4981 - val_accuracy: 0.7532\n",
            "Epoch 703/1000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.7988 - val_loss: 0.4585 - val_accuracy: 0.8052\n",
            "Epoch 704/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8075 - val_loss: 0.4939 - val_accuracy: 0.7532\n",
            "Epoch 705/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.7902 - val_loss: 0.4860 - val_accuracy: 0.7792\n",
            "Epoch 706/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8003 - val_loss: 0.4822 - val_accuracy: 0.7662\n",
            "Epoch 707/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4105 - accuracy: 0.8017 - val_loss: 0.4603 - val_accuracy: 0.7922\n",
            "Epoch 708/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4031 - accuracy: 0.7974 - val_loss: 0.4796 - val_accuracy: 0.7792\n",
            "Epoch 709/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4057 - accuracy: 0.8003 - val_loss: 0.4916 - val_accuracy: 0.7532\n",
            "Epoch 710/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3987 - accuracy: 0.8017 - val_loss: 0.4761 - val_accuracy: 0.8052\n",
            "Epoch 711/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4052 - accuracy: 0.8090 - val_loss: 0.5001 - val_accuracy: 0.7532\n",
            "Epoch 712/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4118 - accuracy: 0.7873 - val_loss: 0.4697 - val_accuracy: 0.7792\n",
            "Epoch 713/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4012 - accuracy: 0.8017 - val_loss: 0.4616 - val_accuracy: 0.7922\n",
            "Epoch 714/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3983 - accuracy: 0.7988 - val_loss: 0.4732 - val_accuracy: 0.8052\n",
            "Epoch 715/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.8046 - val_loss: 0.4677 - val_accuracy: 0.7792\n",
            "Epoch 716/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8017 - val_loss: 0.4692 - val_accuracy: 0.7792\n",
            "Epoch 717/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8032 - val_loss: 0.4786 - val_accuracy: 0.7662\n",
            "Epoch 718/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4108 - accuracy: 0.8090 - val_loss: 0.4688 - val_accuracy: 0.7792\n",
            "Epoch 719/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4016 - accuracy: 0.7988 - val_loss: 0.4900 - val_accuracy: 0.7662\n",
            "Epoch 720/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4029 - accuracy: 0.7959 - val_loss: 0.4662 - val_accuracy: 0.7792\n",
            "Epoch 721/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.7945 - val_loss: 0.5001 - val_accuracy: 0.7792\n",
            "Epoch 722/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4112 - accuracy: 0.8017 - val_loss: 0.4560 - val_accuracy: 0.7792\n",
            "Epoch 723/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4064 - accuracy: 0.8046 - val_loss: 0.4823 - val_accuracy: 0.8182\n",
            "Epoch 724/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4116 - accuracy: 0.7931 - val_loss: 0.4694 - val_accuracy: 0.7792\n",
            "Epoch 725/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4116 - accuracy: 0.7974 - val_loss: 0.4652 - val_accuracy: 0.8052\n",
            "Epoch 726/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4112 - accuracy: 0.7931 - val_loss: 0.4796 - val_accuracy: 0.7792\n",
            "Epoch 727/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4133 - accuracy: 0.8017 - val_loss: 0.4890 - val_accuracy: 0.7532\n",
            "Epoch 728/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4039 - accuracy: 0.8061 - val_loss: 0.4849 - val_accuracy: 0.7532\n",
            "Epoch 729/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4001 - accuracy: 0.8148 - val_loss: 0.4789 - val_accuracy: 0.8052\n",
            "Epoch 730/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.7988 - val_loss: 0.4720 - val_accuracy: 0.8182\n",
            "Epoch 731/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4122 - accuracy: 0.7945 - val_loss: 0.4695 - val_accuracy: 0.7792\n",
            "Epoch 732/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.7945 - val_loss: 0.4699 - val_accuracy: 0.7922\n",
            "Epoch 733/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4004 - accuracy: 0.8032 - val_loss: 0.4673 - val_accuracy: 0.8182\n",
            "Epoch 734/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4040 - accuracy: 0.8017 - val_loss: 0.4942 - val_accuracy: 0.7532\n",
            "Epoch 735/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4049 - accuracy: 0.7988 - val_loss: 0.4781 - val_accuracy: 0.7792\n",
            "Epoch 736/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4015 - accuracy: 0.7974 - val_loss: 0.4880 - val_accuracy: 0.7792\n",
            "Epoch 737/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4064 - accuracy: 0.8090 - val_loss: 0.5043 - val_accuracy: 0.7662\n",
            "Epoch 738/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4013 - accuracy: 0.8061 - val_loss: 0.4739 - val_accuracy: 0.7662\n",
            "Epoch 739/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4038 - accuracy: 0.8061 - val_loss: 0.4736 - val_accuracy: 0.7792\n",
            "Epoch 740/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4051 - accuracy: 0.8046 - val_loss: 0.4779 - val_accuracy: 0.7792\n",
            "Epoch 741/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4083 - accuracy: 0.8133 - val_loss: 0.4840 - val_accuracy: 0.7922\n",
            "Epoch 742/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4151 - accuracy: 0.7873 - val_loss: 0.4674 - val_accuracy: 0.8182\n",
            "Epoch 743/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3954 - accuracy: 0.8090 - val_loss: 0.5140 - val_accuracy: 0.7532\n",
            "Epoch 744/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8032 - val_loss: 0.5064 - val_accuracy: 0.7532\n",
            "Epoch 745/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4079 - accuracy: 0.7945 - val_loss: 0.5128 - val_accuracy: 0.7792\n",
            "Epoch 746/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4056 - accuracy: 0.7887 - val_loss: 0.4772 - val_accuracy: 0.7662\n",
            "Epoch 747/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4020 - accuracy: 0.8046 - val_loss: 0.4933 - val_accuracy: 0.7662\n",
            "Epoch 748/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4083 - accuracy: 0.7916 - val_loss: 0.4785 - val_accuracy: 0.7792\n",
            "Epoch 749/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.7916 - val_loss: 0.5111 - val_accuracy: 0.7403\n",
            "Epoch 750/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.7858 - val_loss: 0.4780 - val_accuracy: 0.8052\n",
            "Epoch 751/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4109 - accuracy: 0.8046 - val_loss: 0.4710 - val_accuracy: 0.8052\n",
            "Epoch 752/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4145 - accuracy: 0.7974 - val_loss: 0.4764 - val_accuracy: 0.7662\n",
            "Epoch 753/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.7916 - val_loss: 0.5019 - val_accuracy: 0.7403\n",
            "Epoch 754/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4125 - accuracy: 0.7902 - val_loss: 0.4702 - val_accuracy: 0.7922\n",
            "Epoch 755/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4023 - accuracy: 0.8061 - val_loss: 0.4814 - val_accuracy: 0.8182\n",
            "Epoch 756/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4081 - accuracy: 0.8017 - val_loss: 0.4684 - val_accuracy: 0.8182\n",
            "Epoch 757/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.7974 - val_loss: 0.4606 - val_accuracy: 0.8182\n",
            "Epoch 758/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4000 - accuracy: 0.8032 - val_loss: 0.4899 - val_accuracy: 0.7922\n",
            "Epoch 759/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4055 - accuracy: 0.7988 - val_loss: 0.4713 - val_accuracy: 0.8052\n",
            "Epoch 760/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3994 - accuracy: 0.8090 - val_loss: 0.4985 - val_accuracy: 0.7662\n",
            "Epoch 761/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.7916 - val_loss: 0.4839 - val_accuracy: 0.8052\n",
            "Epoch 762/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4012 - accuracy: 0.8075 - val_loss: 0.4970 - val_accuracy: 0.7922\n",
            "Epoch 763/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3993 - accuracy: 0.8090 - val_loss: 0.4956 - val_accuracy: 0.7792\n",
            "Epoch 764/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4009 - accuracy: 0.7988 - val_loss: 0.4655 - val_accuracy: 0.7922\n",
            "Epoch 765/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4144 - accuracy: 0.7988 - val_loss: 0.5088 - val_accuracy: 0.7532\n",
            "Epoch 766/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4063 - accuracy: 0.8220 - val_loss: 0.4743 - val_accuracy: 0.7792\n",
            "Epoch 767/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4044 - accuracy: 0.7974 - val_loss: 0.4657 - val_accuracy: 0.8182\n",
            "Epoch 768/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4039 - accuracy: 0.7988 - val_loss: 0.4631 - val_accuracy: 0.7792\n",
            "Epoch 769/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4061 - accuracy: 0.8119 - val_loss: 0.4685 - val_accuracy: 0.8052\n",
            "Epoch 770/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8003 - val_loss: 0.4657 - val_accuracy: 0.8052\n",
            "Epoch 771/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3999 - accuracy: 0.8032 - val_loss: 0.4808 - val_accuracy: 0.8052\n",
            "Epoch 772/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4060 - accuracy: 0.7959 - val_loss: 0.4707 - val_accuracy: 0.7922\n",
            "Epoch 773/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3953 - accuracy: 0.8046 - val_loss: 0.4716 - val_accuracy: 0.7662\n",
            "Epoch 774/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3941 - accuracy: 0.7988 - val_loss: 0.4903 - val_accuracy: 0.7922\n",
            "Epoch 775/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3990 - accuracy: 0.7974 - val_loss: 0.4799 - val_accuracy: 0.7922\n",
            "Epoch 776/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.7959 - val_loss: 0.4965 - val_accuracy: 0.7662\n",
            "Epoch 777/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.7988 - val_loss: 0.4774 - val_accuracy: 0.8052\n",
            "Epoch 778/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.8090 - val_loss: 0.4849 - val_accuracy: 0.7792\n",
            "Epoch 779/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.7931 - val_loss: 0.4781 - val_accuracy: 0.7922\n",
            "Epoch 780/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3958 - accuracy: 0.8061 - val_loss: 0.4731 - val_accuracy: 0.7922\n",
            "Epoch 781/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.7988 - val_loss: 0.4756 - val_accuracy: 0.7922\n",
            "Epoch 782/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3972 - accuracy: 0.8061 - val_loss: 0.5169 - val_accuracy: 0.7662\n",
            "Epoch 783/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4048 - accuracy: 0.8148 - val_loss: 0.4796 - val_accuracy: 0.7792\n",
            "Epoch 784/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3997 - accuracy: 0.8075 - val_loss: 0.4692 - val_accuracy: 0.8182\n",
            "Epoch 785/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3931 - accuracy: 0.8075 - val_loss: 0.4887 - val_accuracy: 0.7792\n",
            "Epoch 786/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.7902 - val_loss: 0.4734 - val_accuracy: 0.7792\n",
            "Epoch 787/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3999 - accuracy: 0.8061 - val_loss: 0.5154 - val_accuracy: 0.7662\n",
            "Epoch 788/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3995 - accuracy: 0.8162 - val_loss: 0.4797 - val_accuracy: 0.7792\n",
            "Epoch 789/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3981 - accuracy: 0.8133 - val_loss: 0.4972 - val_accuracy: 0.7792\n",
            "Epoch 790/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.8075 - val_loss: 0.4832 - val_accuracy: 0.7922\n",
            "Epoch 791/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3993 - accuracy: 0.8104 - val_loss: 0.4684 - val_accuracy: 0.8052\n",
            "Epoch 792/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4025 - accuracy: 0.7959 - val_loss: 0.4706 - val_accuracy: 0.8052\n",
            "Epoch 793/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3995 - accuracy: 0.7988 - val_loss: 0.4658 - val_accuracy: 0.7922\n",
            "Epoch 794/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3962 - accuracy: 0.8133 - val_loss: 0.5109 - val_accuracy: 0.7662\n",
            "Epoch 795/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8003 - val_loss: 0.4669 - val_accuracy: 0.7922\n",
            "Epoch 796/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3925 - accuracy: 0.8075 - val_loss: 0.5060 - val_accuracy: 0.7792\n",
            "Epoch 797/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3965 - accuracy: 0.8003 - val_loss: 0.4752 - val_accuracy: 0.7922\n",
            "Epoch 798/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4048 - accuracy: 0.7974 - val_loss: 0.4931 - val_accuracy: 0.7792\n",
            "Epoch 799/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4125 - accuracy: 0.7873 - val_loss: 0.4655 - val_accuracy: 0.8052\n",
            "Epoch 800/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4013 - accuracy: 0.8075 - val_loss: 0.4782 - val_accuracy: 0.7792\n",
            "Epoch 801/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3979 - accuracy: 0.8075 - val_loss: 0.4711 - val_accuracy: 0.7922\n",
            "Epoch 802/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4008 - accuracy: 0.8061 - val_loss: 0.4760 - val_accuracy: 0.7922\n",
            "Epoch 803/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4001 - accuracy: 0.8046 - val_loss: 0.4740 - val_accuracy: 0.7922\n",
            "Epoch 804/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4020 - accuracy: 0.7988 - val_loss: 0.5095 - val_accuracy: 0.7532\n",
            "Epoch 805/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4115 - accuracy: 0.7959 - val_loss: 0.4820 - val_accuracy: 0.7662\n",
            "Epoch 806/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4028 - accuracy: 0.8090 - val_loss: 0.4786 - val_accuracy: 0.7792\n",
            "Epoch 807/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3956 - accuracy: 0.8003 - val_loss: 0.4796 - val_accuracy: 0.7792\n",
            "Epoch 808/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4014 - accuracy: 0.8177 - val_loss: 0.4960 - val_accuracy: 0.8052\n",
            "Epoch 809/1000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8191 - val_loss: 0.4788 - val_accuracy: 0.7792\n",
            "Epoch 810/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3937 - accuracy: 0.8133 - val_loss: 0.4981 - val_accuracy: 0.7922\n",
            "Epoch 811/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4014 - accuracy: 0.8075 - val_loss: 0.5320 - val_accuracy: 0.7792\n",
            "Epoch 812/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.7902 - val_loss: 0.5259 - val_accuracy: 0.7792\n",
            "Epoch 813/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3990 - accuracy: 0.8104 - val_loss: 0.4927 - val_accuracy: 0.7792\n",
            "Epoch 814/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.7974 - val_loss: 0.4923 - val_accuracy: 0.7922\n",
            "Epoch 815/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3932 - accuracy: 0.8133 - val_loss: 0.4763 - val_accuracy: 0.8052\n",
            "Epoch 816/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3930 - accuracy: 0.8046 - val_loss: 0.4798 - val_accuracy: 0.8052\n",
            "Epoch 817/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3980 - accuracy: 0.7988 - val_loss: 0.4881 - val_accuracy: 0.7792\n",
            "Epoch 818/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3994 - accuracy: 0.7988 - val_loss: 0.4688 - val_accuracy: 0.8182\n",
            "Epoch 819/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3993 - accuracy: 0.8061 - val_loss: 0.4819 - val_accuracy: 0.7792\n",
            "Epoch 820/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3915 - accuracy: 0.8133 - val_loss: 0.4858 - val_accuracy: 0.7922\n",
            "Epoch 821/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3962 - accuracy: 0.8032 - val_loss: 0.4795 - val_accuracy: 0.8052\n",
            "Epoch 822/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3976 - accuracy: 0.8032 - val_loss: 0.4763 - val_accuracy: 0.8052\n",
            "Epoch 823/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3958 - accuracy: 0.8046 - val_loss: 0.5112 - val_accuracy: 0.7662\n",
            "Epoch 824/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4107 - accuracy: 0.7945 - val_loss: 0.5122 - val_accuracy: 0.7792\n",
            "Epoch 825/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3899 - accuracy: 0.8205 - val_loss: 0.4893 - val_accuracy: 0.7662\n",
            "Epoch 826/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3995 - accuracy: 0.8017 - val_loss: 0.4860 - val_accuracy: 0.7792\n",
            "Epoch 827/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8191 - val_loss: 0.4837 - val_accuracy: 0.8052\n",
            "Epoch 828/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4011 - accuracy: 0.8075 - val_loss: 0.4788 - val_accuracy: 0.7922\n",
            "Epoch 829/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3895 - accuracy: 0.8177 - val_loss: 0.4866 - val_accuracy: 0.7792\n",
            "Epoch 830/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3966 - accuracy: 0.8003 - val_loss: 0.5108 - val_accuracy: 0.7922\n",
            "Epoch 831/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3957 - accuracy: 0.8177 - val_loss: 0.5458 - val_accuracy: 0.7662\n",
            "Epoch 832/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4001 - accuracy: 0.8119 - val_loss: 0.4791 - val_accuracy: 0.7792\n",
            "Epoch 833/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3969 - accuracy: 0.8061 - val_loss: 0.4923 - val_accuracy: 0.7792\n",
            "Epoch 834/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3927 - accuracy: 0.8061 - val_loss: 0.4730 - val_accuracy: 0.7792\n",
            "Epoch 835/1000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.8119 - val_loss: 0.4761 - val_accuracy: 0.7922\n",
            "Epoch 836/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3970 - accuracy: 0.8061 - val_loss: 0.4899 - val_accuracy: 0.7792\n",
            "Epoch 837/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3842 - accuracy: 0.8234 - val_loss: 0.4995 - val_accuracy: 0.8052\n",
            "Epoch 838/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.8046 - val_loss: 0.4793 - val_accuracy: 0.8052\n",
            "Epoch 839/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4060 - accuracy: 0.7988 - val_loss: 0.4855 - val_accuracy: 0.8052\n",
            "Epoch 840/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3955 - accuracy: 0.8061 - val_loss: 0.4799 - val_accuracy: 0.8052\n",
            "Epoch 841/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3898 - accuracy: 0.8061 - val_loss: 0.4942 - val_accuracy: 0.7922\n",
            "Epoch 842/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4012 - accuracy: 0.8046 - val_loss: 0.4722 - val_accuracy: 0.8052\n",
            "Epoch 843/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3972 - accuracy: 0.8090 - val_loss: 0.5062 - val_accuracy: 0.7662\n",
            "Epoch 844/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3956 - accuracy: 0.8075 - val_loss: 0.4932 - val_accuracy: 0.7792\n",
            "Epoch 845/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3994 - accuracy: 0.8061 - val_loss: 0.4867 - val_accuracy: 0.7792\n",
            "Epoch 846/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4008 - accuracy: 0.8046 - val_loss: 0.4916 - val_accuracy: 0.7662\n",
            "Epoch 847/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3933 - accuracy: 0.8032 - val_loss: 0.4989 - val_accuracy: 0.7792\n",
            "Epoch 848/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3922 - accuracy: 0.8162 - val_loss: 0.4808 - val_accuracy: 0.7792\n",
            "Epoch 849/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4036 - accuracy: 0.7988 - val_loss: 0.5203 - val_accuracy: 0.7532\n",
            "Epoch 850/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3985 - accuracy: 0.8090 - val_loss: 0.5756 - val_accuracy: 0.7532\n",
            "Epoch 851/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4025 - accuracy: 0.8090 - val_loss: 0.4986 - val_accuracy: 0.7922\n",
            "Epoch 852/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3927 - accuracy: 0.8191 - val_loss: 0.5093 - val_accuracy: 0.7922\n",
            "Epoch 853/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3918 - accuracy: 0.8046 - val_loss: 0.4992 - val_accuracy: 0.7922\n",
            "Epoch 854/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3929 - accuracy: 0.8220 - val_loss: 0.4820 - val_accuracy: 0.7922\n",
            "Epoch 855/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3947 - accuracy: 0.8090 - val_loss: 0.5014 - val_accuracy: 0.7922\n",
            "Epoch 856/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8046 - val_loss: 0.5454 - val_accuracy: 0.7532\n",
            "Epoch 857/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8032 - val_loss: 0.4909 - val_accuracy: 0.7922\n",
            "Epoch 858/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3922 - accuracy: 0.8220 - val_loss: 0.4812 - val_accuracy: 0.8052\n",
            "Epoch 859/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3879 - accuracy: 0.8090 - val_loss: 0.4852 - val_accuracy: 0.8052\n",
            "Epoch 860/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3948 - accuracy: 0.8017 - val_loss: 0.4815 - val_accuracy: 0.8182\n",
            "Epoch 861/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3904 - accuracy: 0.8075 - val_loss: 0.4861 - val_accuracy: 0.8182\n",
            "Epoch 862/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3915 - accuracy: 0.8148 - val_loss: 0.5039 - val_accuracy: 0.7922\n",
            "Epoch 863/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3897 - accuracy: 0.8220 - val_loss: 0.5254 - val_accuracy: 0.7662\n",
            "Epoch 864/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4020 - accuracy: 0.8061 - val_loss: 0.4977 - val_accuracy: 0.7922\n",
            "Epoch 865/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3942 - accuracy: 0.8119 - val_loss: 0.4840 - val_accuracy: 0.7922\n",
            "Epoch 866/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3978 - accuracy: 0.8104 - val_loss: 0.4950 - val_accuracy: 0.7792\n",
            "Epoch 867/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3935 - accuracy: 0.8104 - val_loss: 0.4901 - val_accuracy: 0.8052\n",
            "Epoch 868/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3970 - accuracy: 0.8090 - val_loss: 0.4894 - val_accuracy: 0.7922\n",
            "Epoch 869/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3922 - accuracy: 0.8046 - val_loss: 0.5034 - val_accuracy: 0.7792\n",
            "Epoch 870/1000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3906 - accuracy: 0.8104 - val_loss: 0.5145 - val_accuracy: 0.7792\n",
            "Epoch 871/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3958 - accuracy: 0.8133 - val_loss: 0.4830 - val_accuracy: 0.7922\n",
            "Epoch 872/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3918 - accuracy: 0.8104 - val_loss: 0.5163 - val_accuracy: 0.7792\n",
            "Epoch 873/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3957 - accuracy: 0.8090 - val_loss: 0.4769 - val_accuracy: 0.8052\n",
            "Epoch 874/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3982 - accuracy: 0.7974 - val_loss: 0.4881 - val_accuracy: 0.8052\n",
            "Epoch 875/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3900 - accuracy: 0.8162 - val_loss: 0.4883 - val_accuracy: 0.8052\n",
            "Epoch 876/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3945 - accuracy: 0.8148 - val_loss: 0.4844 - val_accuracy: 0.8182\n",
            "Epoch 877/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3928 - accuracy: 0.8104 - val_loss: 0.4919 - val_accuracy: 0.8182\n",
            "Epoch 878/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3987 - accuracy: 0.8090 - val_loss: 0.4953 - val_accuracy: 0.7922\n",
            "Epoch 879/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3997 - accuracy: 0.8032 - val_loss: 0.5879 - val_accuracy: 0.7662\n",
            "Epoch 880/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7974 - val_loss: 0.5216 - val_accuracy: 0.7922\n",
            "Epoch 881/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.7959 - val_loss: 0.5312 - val_accuracy: 0.7792\n",
            "Epoch 882/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4138 - accuracy: 0.7959 - val_loss: 0.4789 - val_accuracy: 0.8052\n",
            "Epoch 883/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3963 - accuracy: 0.8017 - val_loss: 0.5114 - val_accuracy: 0.7922\n",
            "Epoch 884/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3952 - accuracy: 0.8075 - val_loss: 0.4814 - val_accuracy: 0.8182\n",
            "Epoch 885/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.8046 - val_loss: 0.4867 - val_accuracy: 0.7922\n",
            "Epoch 886/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3902 - accuracy: 0.8104 - val_loss: 0.4987 - val_accuracy: 0.7922\n",
            "Epoch 887/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3926 - accuracy: 0.8133 - val_loss: 0.4868 - val_accuracy: 0.7922\n",
            "Epoch 888/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3886 - accuracy: 0.8104 - val_loss: 0.4865 - val_accuracy: 0.8052\n",
            "Epoch 889/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3859 - accuracy: 0.8162 - val_loss: 0.4862 - val_accuracy: 0.8052\n",
            "Epoch 890/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3992 - accuracy: 0.8133 - val_loss: 0.4949 - val_accuracy: 0.8052\n",
            "Epoch 891/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3991 - accuracy: 0.7974 - val_loss: 0.4800 - val_accuracy: 0.7922\n",
            "Epoch 892/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3880 - accuracy: 0.8133 - val_loss: 0.4944 - val_accuracy: 0.7922\n",
            "Epoch 893/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3920 - accuracy: 0.8017 - val_loss: 0.5110 - val_accuracy: 0.8052\n",
            "Epoch 894/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3971 - accuracy: 0.8017 - val_loss: 0.4966 - val_accuracy: 0.7922\n",
            "Epoch 895/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3863 - accuracy: 0.8119 - val_loss: 0.4916 - val_accuracy: 0.8052\n",
            "Epoch 896/1000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3887 - accuracy: 0.8177 - val_loss: 0.4969 - val_accuracy: 0.7922\n",
            "Epoch 897/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3912 - accuracy: 0.8104 - val_loss: 0.4817 - val_accuracy: 0.8052\n",
            "Epoch 898/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3895 - accuracy: 0.8046 - val_loss: 0.4997 - val_accuracy: 0.8052\n",
            "Epoch 899/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3894 - accuracy: 0.8090 - val_loss: 0.4902 - val_accuracy: 0.7922\n",
            "Epoch 900/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4005 - accuracy: 0.8032 - val_loss: 0.5201 - val_accuracy: 0.7922\n",
            "Epoch 901/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3994 - accuracy: 0.8090 - val_loss: 0.4875 - val_accuracy: 0.8052\n",
            "Epoch 902/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3956 - accuracy: 0.8032 - val_loss: 0.4914 - val_accuracy: 0.8052\n",
            "Epoch 903/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3981 - accuracy: 0.8191 - val_loss: 0.4806 - val_accuracy: 0.8182\n",
            "Epoch 904/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3985 - accuracy: 0.8032 - val_loss: 0.5027 - val_accuracy: 0.8052\n",
            "Epoch 905/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3984 - accuracy: 0.8003 - val_loss: 0.4716 - val_accuracy: 0.8182\n",
            "Epoch 906/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3962 - accuracy: 0.8046 - val_loss: 0.4953 - val_accuracy: 0.7792\n",
            "Epoch 907/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3839 - accuracy: 0.8090 - val_loss: 0.5093 - val_accuracy: 0.7922\n",
            "Epoch 908/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3945 - accuracy: 0.8133 - val_loss: 0.4932 - val_accuracy: 0.7922\n",
            "Epoch 909/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3867 - accuracy: 0.8220 - val_loss: 0.5036 - val_accuracy: 0.7922\n",
            "Epoch 910/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.8061 - val_loss: 0.5069 - val_accuracy: 0.7922\n",
            "Epoch 911/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3888 - accuracy: 0.8205 - val_loss: 0.4917 - val_accuracy: 0.8182\n",
            "Epoch 912/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3875 - accuracy: 0.8205 - val_loss: 0.5022 - val_accuracy: 0.8182\n",
            "Epoch 913/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3891 - accuracy: 0.8177 - val_loss: 0.5092 - val_accuracy: 0.7922\n",
            "Epoch 914/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3903 - accuracy: 0.8133 - val_loss: 0.4873 - val_accuracy: 0.7922\n",
            "Epoch 915/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3900 - accuracy: 0.8090 - val_loss: 0.5476 - val_accuracy: 0.7922\n",
            "Epoch 916/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4088 - accuracy: 0.7988 - val_loss: 0.5257 - val_accuracy: 0.8052\n",
            "Epoch 917/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3860 - accuracy: 0.8119 - val_loss: 0.4919 - val_accuracy: 0.8182\n",
            "Epoch 918/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3957 - accuracy: 0.8075 - val_loss: 0.4979 - val_accuracy: 0.8182\n",
            "Epoch 919/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4025 - accuracy: 0.7959 - val_loss: 0.4912 - val_accuracy: 0.8052\n",
            "Epoch 920/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4021 - accuracy: 0.8177 - val_loss: 0.4910 - val_accuracy: 0.8052\n",
            "Epoch 921/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3972 - accuracy: 0.8090 - val_loss: 0.4786 - val_accuracy: 0.8052\n",
            "Epoch 922/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3852 - accuracy: 0.8017 - val_loss: 0.5202 - val_accuracy: 0.8052\n",
            "Epoch 923/1000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.7916 - val_loss: 0.5943 - val_accuracy: 0.7403\n",
            "Epoch 924/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3942 - accuracy: 0.8003 - val_loss: 0.5284 - val_accuracy: 0.7662\n",
            "Epoch 925/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.7988 - val_loss: 0.5367 - val_accuracy: 0.7792\n",
            "Epoch 926/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3983 - accuracy: 0.8003 - val_loss: 0.5086 - val_accuracy: 0.8182\n",
            "Epoch 927/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3802 - accuracy: 0.8090 - val_loss: 0.4875 - val_accuracy: 0.8052\n",
            "Epoch 928/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3809 - accuracy: 0.8119 - val_loss: 0.5478 - val_accuracy: 0.7662\n",
            "Epoch 929/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4029 - accuracy: 0.8017 - val_loss: 0.4983 - val_accuracy: 0.8182\n",
            "Epoch 930/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3886 - accuracy: 0.8148 - val_loss: 0.4836 - val_accuracy: 0.8052\n",
            "Epoch 931/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3862 - accuracy: 0.8148 - val_loss: 0.5208 - val_accuracy: 0.7922\n",
            "Epoch 932/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4030 - accuracy: 0.8017 - val_loss: 0.4850 - val_accuracy: 0.8182\n",
            "Epoch 933/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3972 - accuracy: 0.8061 - val_loss: 0.4807 - val_accuracy: 0.8182\n",
            "Epoch 934/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3917 - accuracy: 0.8003 - val_loss: 0.4984 - val_accuracy: 0.8052\n",
            "Epoch 935/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3989 - accuracy: 0.8017 - val_loss: 0.4977 - val_accuracy: 0.7922\n",
            "Epoch 936/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3967 - accuracy: 0.8046 - val_loss: 0.4935 - val_accuracy: 0.8182\n",
            "Epoch 937/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3858 - accuracy: 0.8177 - val_loss: 0.5366 - val_accuracy: 0.7792\n",
            "Epoch 938/1000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3894 - accuracy: 0.8133 - val_loss: 0.5021 - val_accuracy: 0.8052\n",
            "Epoch 939/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3865 - accuracy: 0.8148 - val_loss: 0.4957 - val_accuracy: 0.8182\n",
            "Epoch 940/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3934 - accuracy: 0.8032 - val_loss: 0.5338 - val_accuracy: 0.7922\n",
            "Epoch 941/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4025 - accuracy: 0.7974 - val_loss: 0.5224 - val_accuracy: 0.8052\n",
            "Epoch 942/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3866 - accuracy: 0.8162 - val_loss: 0.5072 - val_accuracy: 0.7922\n",
            "Epoch 943/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3943 - accuracy: 0.8133 - val_loss: 0.5245 - val_accuracy: 0.7662\n",
            "Epoch 944/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3983 - accuracy: 0.7974 - val_loss: 0.5376 - val_accuracy: 0.7662\n",
            "Epoch 945/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8017 - val_loss: 0.5176 - val_accuracy: 0.7922\n",
            "Epoch 946/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3879 - accuracy: 0.8119 - val_loss: 0.5062 - val_accuracy: 0.7792\n",
            "Epoch 947/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3868 - accuracy: 0.8205 - val_loss: 0.4876 - val_accuracy: 0.8052\n",
            "Epoch 948/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3951 - accuracy: 0.8133 - val_loss: 0.4983 - val_accuracy: 0.8182\n",
            "Epoch 949/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3830 - accuracy: 0.8191 - val_loss: 0.4895 - val_accuracy: 0.8182\n",
            "Epoch 950/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3839 - accuracy: 0.8220 - val_loss: 0.4946 - val_accuracy: 0.8052\n",
            "Epoch 951/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3962 - accuracy: 0.8104 - val_loss: 0.5038 - val_accuracy: 0.8312\n",
            "Epoch 952/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3897 - accuracy: 0.8191 - val_loss: 0.4897 - val_accuracy: 0.8052\n",
            "Epoch 953/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3877 - accuracy: 0.8119 - val_loss: 0.4951 - val_accuracy: 0.7922\n",
            "Epoch 954/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3855 - accuracy: 0.8133 - val_loss: 0.4928 - val_accuracy: 0.8182\n",
            "Epoch 955/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3850 - accuracy: 0.8177 - val_loss: 0.4939 - val_accuracy: 0.8182\n",
            "Epoch 956/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3843 - accuracy: 0.8090 - val_loss: 0.4995 - val_accuracy: 0.7922\n",
            "Epoch 957/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3849 - accuracy: 0.8133 - val_loss: 0.5011 - val_accuracy: 0.8182\n",
            "Epoch 958/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3807 - accuracy: 0.8205 - val_loss: 0.4894 - val_accuracy: 0.7922\n",
            "Epoch 959/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3854 - accuracy: 0.8104 - val_loss: 0.4926 - val_accuracy: 0.8052\n",
            "Epoch 960/1000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.7974 - val_loss: 0.4943 - val_accuracy: 0.8052\n",
            "Epoch 961/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3860 - accuracy: 0.8003 - val_loss: 0.5006 - val_accuracy: 0.7922\n",
            "Epoch 962/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3886 - accuracy: 0.8177 - val_loss: 0.5147 - val_accuracy: 0.8052\n",
            "Epoch 963/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4012 - accuracy: 0.8148 - val_loss: 0.5083 - val_accuracy: 0.7922\n",
            "Epoch 964/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3893 - accuracy: 0.8104 - val_loss: 0.4927 - val_accuracy: 0.7922\n",
            "Epoch 965/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3868 - accuracy: 0.8307 - val_loss: 0.5026 - val_accuracy: 0.8052\n",
            "Epoch 966/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3896 - accuracy: 0.8104 - val_loss: 0.5265 - val_accuracy: 0.8052\n",
            "Epoch 967/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3979 - accuracy: 0.8075 - val_loss: 0.5036 - val_accuracy: 0.8182\n",
            "Epoch 968/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3817 - accuracy: 0.8191 - val_loss: 0.5171 - val_accuracy: 0.8182\n",
            "Epoch 969/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3966 - accuracy: 0.8148 - val_loss: 0.5554 - val_accuracy: 0.7792\n",
            "Epoch 970/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.8046 - val_loss: 0.5165 - val_accuracy: 0.8182\n",
            "Epoch 971/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3863 - accuracy: 0.8162 - val_loss: 0.5231 - val_accuracy: 0.7792\n",
            "Epoch 972/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3855 - accuracy: 0.8104 - val_loss: 0.5116 - val_accuracy: 0.7792\n",
            "Epoch 973/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3938 - accuracy: 0.8075 - val_loss: 0.5138 - val_accuracy: 0.7922\n",
            "Epoch 974/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3998 - accuracy: 0.8104 - val_loss: 0.5240 - val_accuracy: 0.8182\n",
            "Epoch 975/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3929 - accuracy: 0.8032 - val_loss: 0.4998 - val_accuracy: 0.7922\n",
            "Epoch 976/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3968 - accuracy: 0.8017 - val_loss: 0.5223 - val_accuracy: 0.7792\n",
            "Epoch 977/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4132 - accuracy: 0.8075 - val_loss: 0.5218 - val_accuracy: 0.8182\n",
            "Epoch 978/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3944 - accuracy: 0.8148 - val_loss: 0.4900 - val_accuracy: 0.8182\n",
            "Epoch 979/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3979 - accuracy: 0.8003 - val_loss: 0.4925 - val_accuracy: 0.7922\n",
            "Epoch 980/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3849 - accuracy: 0.8119 - val_loss: 0.4912 - val_accuracy: 0.7922\n",
            "Epoch 981/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3851 - accuracy: 0.8090 - val_loss: 0.4857 - val_accuracy: 0.8052\n",
            "Epoch 982/1000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3870 - accuracy: 0.8205 - val_loss: 0.4926 - val_accuracy: 0.8052\n",
            "Epoch 983/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3917 - accuracy: 0.7916 - val_loss: 0.5467 - val_accuracy: 0.7922\n",
            "Epoch 984/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3900 - accuracy: 0.7988 - val_loss: 0.5148 - val_accuracy: 0.7922\n",
            "Epoch 985/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3838 - accuracy: 0.8148 - val_loss: 0.5178 - val_accuracy: 0.8052\n",
            "Epoch 986/1000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3876 - accuracy: 0.8148 - val_loss: 0.4831 - val_accuracy: 0.8052\n",
            "Epoch 987/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3871 - accuracy: 0.8003 - val_loss: 0.5021 - val_accuracy: 0.8052\n",
            "Epoch 988/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3978 - accuracy: 0.7974 - val_loss: 0.4909 - val_accuracy: 0.8052\n",
            "Epoch 989/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3839 - accuracy: 0.8032 - val_loss: 0.5293 - val_accuracy: 0.7922\n",
            "Epoch 990/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3875 - accuracy: 0.8162 - val_loss: 0.5020 - val_accuracy: 0.7922\n",
            "Epoch 991/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3888 - accuracy: 0.8177 - val_loss: 0.4973 - val_accuracy: 0.7922\n",
            "Epoch 992/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3836 - accuracy: 0.8046 - val_loss: 0.5136 - val_accuracy: 0.8182\n",
            "Epoch 993/1000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3772 - accuracy: 0.8177 - val_loss: 0.4959 - val_accuracy: 0.8312\n",
            "Epoch 994/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3866 - accuracy: 0.8148 - val_loss: 0.4933 - val_accuracy: 0.8052\n",
            "Epoch 995/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3870 - accuracy: 0.8003 - val_loss: 0.4923 - val_accuracy: 0.8182\n",
            "Epoch 996/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3815 - accuracy: 0.8177 - val_loss: 0.5143 - val_accuracy: 0.7922\n",
            "Epoch 997/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3777 - accuracy: 0.8119 - val_loss: 0.4856 - val_accuracy: 0.8182\n",
            "Epoch 998/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3915 - accuracy: 0.8075 - val_loss: 0.5087 - val_accuracy: 0.8052\n",
            "Epoch 999/1000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3950 - accuracy: 0.8003 - val_loss: 0.4794 - val_accuracy: 0.8052\n",
            "Epoch 1000/1000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3927 - accuracy: 0.8162 - val_loss: 0.5008 - val_accuracy: 0.8182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Revisando el entrenamiento"
      ],
      "metadata": {
        "id": "bjJtY12MTlxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc= history.history['accuracy']\n",
        "loss= history.history['loss']\n",
        "acc_val= history.history['val_accuracy']\n",
        "loss_val= history.history['val_loss']\n",
        "\n",
        "def graficar(val_1, val_2, titulo, ylabel):\n",
        "  epochs= np.arange(len(history.history['accuracy']))\n",
        "  plt.plot(epochs, val_1, 'g', label= 'Ent')\n",
        "  plt.plot(epochs, val_2, 'b', label= 'Val')\n",
        "  plt.xlabel('Epoca')\n",
        "  plt.ylabel(ylabel)\n",
        "  plt.title(titulo)\n",
        "  plt.legend(loc='lower right')\n",
        "  plt.show()\n",
        "\n",
        "graficar(acc, acc_val, 'Exactitud ent y val', 'Exactitud')\n",
        "graficar(loss, loss_val, 'Loss ent y val', 'Loss')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "d15w7JagZ4ea",
        "outputId": "c5a4eb5a-f545-4a39-ed26-6dc426d0945f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vCK7-6Oshfyw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}